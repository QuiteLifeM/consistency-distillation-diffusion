"""
–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è
"""
import matplotlib.pyplot as plt
import torch
import os
import glob

def plot_loss_curve(loss_history=None, save_path="training_loss.png"):
    """
    –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ loss'–∞
    """
    if loss_history is None:
        print("‚ö†Ô∏è –ò—Å—Ç–æ—Ä–∏—è loss'–æ–≤ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–∞")
        return
    
    plt.figure(figsize=(10, 6))
    plt.plot(range(1, len(loss_history) + 1), loss_history, 
             marker='o', linewidth=2, markersize=6, color='blue')
    plt.xlabel('–≠–ø–æ—Ö–∞', fontsize=12)
    plt.ylabel('Loss', fontsize=12)
    plt.title('Consistency Distillation Training Loss', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"‚úÖ –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
    plt.close()


def analyze_checkpoints():
    """
    –ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
    """
    print("="*60)
    print("–ê–Ω–∞–ª–∏–∑ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤")
    print("="*60)
    
    checkpoint_files = sorted(glob.glob("student_checkpoint_epoch_*.pt"))
    
    if not checkpoint_files:
        print("‚ö†Ô∏è –ß–µ–∫–ø–æ–∏–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    print(f"\n–ù–∞–π–¥–µ–Ω–æ {len(checkpoint_files)} —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤:")
    
    for cp_file in checkpoint_files:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç
        checkpoint = torch.load(cp_file, map_location="cpu")
        
        # –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        file_size = os.path.getsize(cp_file) / (1024**2)  # MB
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        num_params = sum(p.numel() for p in checkpoint.values())
        
        print(f"\n  üìÅ {cp_file}")
        print(f"     –†–∞–∑–º–µ—Ä: {file_size:.1f} MB")
        print(f"     –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {num_params:,}")
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
    if os.path.exists("student_final.pt"):
        final_checkpoint = torch.load("student_final.pt", map_location="cpu")
        file_size = os.path.getsize("student_final.pt") / (1024**2)
        num_params = sum(p.numel() for p in final_checkpoint.values())
        
        print(f"\n  üìÅ student_final.pt (—Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å)")
        print(f"     –†–∞–∑–º–µ—Ä: {file_size:.1f} MB")
        print(f"     –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {num_params:,}")
    
    print("\n" + "="*60)


def compare_model_sizes():
    """
    –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ —É—á–∏—Ç–µ–ª—è –∏ —Å—Ç—É–¥–µ–Ω—Ç–∞
    """
    print("="*60)
    print("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ –º–æ–¥–µ–ª–µ–π")
    print("="*60)
    
    teacher_path = "./micro_diffusion/trained_models/teacher.pt"
    student_path = "student_final.pt"
    
    if os.path.exists(teacher_path):
        teacher_size = os.path.getsize(teacher_path) / (1024**2)
        teacher_checkpoint = torch.load(teacher_path, map_location="cpu")
        teacher_params = sum(p.numel() for p in teacher_checkpoint.values())
        
        print(f"\nüë®‚Äçüè´ –£—á–∏—Ç–µ–ª—å (teacher.pt):")
        print(f"   –†–∞–∑–º–µ—Ä: {teacher_size:.1f} MB")
        print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {teacher_params:,}")
    else:
        print(f"\n‚ö†Ô∏è –£—á–∏—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω: {teacher_path}")
    
    if os.path.exists(student_path):
        student_size = os.path.getsize(student_path) / (1024**2)
        student_checkpoint = torch.load(student_path, map_location="cpu")
        student_params = sum(p.numel() for p in student_checkpoint.values())
        
        print(f"\nüë®‚Äçüéì –°—Ç—É–¥–µ–Ω—Ç (student_final.pt):")
        print(f"   –†–∞–∑–º–µ—Ä: {student_size:.1f} MB")
        print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {student_params:,}")
        
        if os.path.exists(teacher_path):
            print(f"\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ:")
            print(f"   –†–∞–∑–º–µ—Ä: –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π ({student_size:.1f} MB)")
            print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: –æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ ({student_params:,})")
            print(f"   –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ: —Å—Ç—É–¥–µ–Ω—Ç –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –±—ã—Å—Ç—Ä–µ–µ (–º–µ–Ω—å—à–µ —à–∞–≥–æ–≤)")
    else:
        print(f"\n‚ö†Ô∏è –°—Ç—É–¥–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {student_path}")
        print("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ train.py –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
    
    print("\n" + "="*60)


def plot_multiple_metrics(metrics_dict, save_path="training_metrics.png"):
    """
    –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫ –Ω–∞ –æ–¥–Ω–æ–º –≥—Ä–∞—Ñ–∏–∫–µ
    
    Args:
        metrics_dict: —Å–ª–æ–≤–∞—Ä—å {–Ω–∞–∑–≤–∞–Ω–∏–µ: [–∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —ç–ø–æ—Ö–∞–º]}
    """
    plt.figure(figsize=(12, 6))
    
    for name, values in metrics_dict.items():
        plt.plot(range(1, len(values) + 1), values, 
                marker='o', linewidth=2, label=name)
    
    plt.xlabel('–≠–ø–æ—Ö–∞', fontsize=12)
    plt.ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ', fontsize=12)
    plt.title('–ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è', fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"‚úÖ –ì—Ä–∞—Ñ–∏–∫ –º–µ—Ç—Ä–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
    plt.close()


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è")
    parser.add_argument("--mode", choices=["checkpoints", "compare", "all"], 
                        default="all",
                        help="–†–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞")
    
    args = parser.parse_args()
    
    if args.mode in ["checkpoints", "all"]:
        analyze_checkpoints()
    
    if args.mode in ["compare", "all"]:
        compare_model_sizes()
    
    print("\nüí° –°–æ–≤–µ—Ç: –î–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ loss'–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫ training_loss.png,")
    print("   –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è.")




