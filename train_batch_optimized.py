import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
from micro_diffusion.micro_diffusion.models.model import create_latent_diffusion

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è CPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

# =======================
# Dataset –¥–ª—è –ø—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã—Ö –ª–∞—Ç–µ–Ω—Ç–æ–≤
# =======================
class LatentPromptDataset(Dataset):
    """Dataset –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã—Ö –ª–∞—Ç–µ–Ω—Ç–æ–≤ –∏ –ø—Ä–æ–º–ø—Ç–æ–≤"""
    def __init__(self, latents_dir, prompts_dir):
        self.latents_dir = latents_dir
        self.prompts_dir = prompts_dir
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ —Ñ–∞–π–ª–æ–≤
        self.latent_files = sorted([f for f in os.listdir(latents_dir) if f.endswith('.pt')])
        self.prompt_files = sorted([f for f in os.listdir(prompts_dir) if f.endswith('.txt')])
        
        assert len(self.latent_files) == len(self.prompt_files), \
            f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∞—Ç–µ–Ω—Ç–æ–≤ ({len(self.latent_files)}) != –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–º–ø—Ç–æ–≤ ({len(self.prompt_files)})"
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.latent_files)} –ª–∞—Ç–µ–Ω—Ç–æ–≤ –∏ –ø—Ä–æ–º–ø—Ç–æ–≤")

    def __len__(self):
        return len(self.latent_files)

    def __getitem__(self, idx):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª–∞—Ç–µ–Ω—Ç
        latent_path = os.path.join(self.latents_dir, self.latent_files[idx])
        latent = torch.load(latent_path)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç
        prompt_path = os.path.join(self.prompts_dir, self.prompt_files[idx])
        with open(prompt_path, 'r', encoding='utf-8') as f:
            prompt = f.read().strip()
        
        return latent, prompt

# =======================
# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è Consistency Distillation –Ω–∞ CPU (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
# =======================
def get_text_embeddings(prompts, model):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å"""
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —ç–Ω–∫–æ–¥–µ—Ä –º–æ–¥–µ–ª–∏
    tokenized = model.tokenizer.tokenize(prompts)
    device = next(model.parameters()).device
    input_ids = tokenized['input_ids'].to(device)
    
    with torch.no_grad():
        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —á–µ—Ä–µ–∑ text_encoder –º–æ–¥–µ–ª–∏
        text_embeddings = model.text_encoder.encode(input_ids)[0]
    
    return text_embeddings  # –û—Å—Ç–∞–≤–ª—è–µ–º –Ω–∞ —Ç–æ–º –∂–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ (CPU)

def consistency_distillation_step_batch_optimized(latents, text_embeddings, teacher_model, student_model):
    """
    –û–¥–∏–Ω —à–∞–≥ Consistency Distillation –Ω–∞ CPU (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –±–æ–ª—å—à–∏–º batch_size)
    """
    batch_size = latents.shape[0]
    
    # –°—ç–º–ø–ª–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å —à—É–º–∞ –∏–∑ EDM —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    rnd_normal = torch.randn([batch_size, 1, 1, 1], device=latents.device)
    sigma = (rnd_normal * teacher_model.edm_config.P_std + teacher_model.edm_config.P_mean).exp()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —à—É–º –∫ —á–∏—Å—Ç—ã–º –ª–∞—Ç–µ–Ω—Ç–∞–º
    noise = torch.randn_like(latents) * sigma
    noisy_latents = latents + noise
    
    # Teacher: –¥–µ–ª–∞–µ—Ç –æ–¥–∏–Ω —à–∞–≥ –¥–µ–Ω–æ–π–∑–∏–Ω–≥–∞ —Å —Ç–µ–∫—É—â–µ–≥–æ —É—Ä–æ–≤–Ω—è —à—É–º–∞
    with torch.no_grad():
        teacher_output = teacher_model.model_forward_wrapper(
            noisy_latents,
            sigma,
            text_embeddings,
            teacher_model.dit,
            mask_ratio=0.0
        )
        teacher_denoised = teacher_output['sample']
    
    # Student: —Ç–∞–∫–∂–µ –¥–µ–ª–∞–µ—Ç –æ–¥–∏–Ω —à–∞–≥ –¥–µ–Ω–æ–π–∑–∏–Ω–≥–∞
    student_output = student_model.model_forward_wrapper(
        noisy_latents,
        sigma,
        text_embeddings,
        student_model.dit,
        mask_ratio=0.0
    )
    student_denoised = student_output['sample']
    
    # Consistency loss: —Å—Ç—É–¥–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Ç–æ –∂–µ, —á—Ç–æ –∏ —É—á–∏—Ç–µ–ª—å
    loss = nn.MSELoss()(student_denoised, teacher_denoised)
    
    return loss

# =======================
# –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π —Ü–∏–∫–ª (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
# =======================
def custom_collate(batch):
    """
    –ö–∞—Å—Ç–æ–º–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–∞—Ç—á–µ–π
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ª–∞—Ç–µ–Ω—Ç—ã —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–æ–º–ø—Ç—ã
    """
    latents_list = []
    prompts_list = []
    
    for latent, prompt in batch:
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –ª–∞—Ç–µ–Ω—Ç –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å [C, H, W]
        if latent.dim() == 4 and latent.shape[0] == 1:
            latent = latent.squeeze(0)  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω—é—é batch dimension
        
        latents_list.append(latent)
        prompts_list.append(prompt)
    
    # –°—Ç–∞–∫–∞–µ–º –ª–∞—Ç–µ–Ω—Ç—ã –≤ –±–∞—Ç—á [B, C, H, W]
    latents_batch = torch.stack(latents_list, dim=0)
    
    return latents_batch, prompts_list

def train_consistency_distillation_batch_optimized(dataloader, teacher_model, student_model, optimizer, num_epochs=5):
    """
    –û–±—É—á–µ–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ Consistency Distillation –Ω–∞ CPU (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
    """
    losses_history = []
    
    print(f"\n{'='*60}")
    print(f"–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ CPU (–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –í–ï–†–°–ò–Ø): {num_epochs} —ç–ø–æ—Ö, {len(dataloader)} –±–∞—Ç—á–µ–π –Ω–∞ —ç–ø–æ—Ö—É")
    print(f"üöÄ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò: batch_size=4, num_workers=0, float32, 5 —ç–ø–æ—Ö")
    print(f"‚è±Ô∏è  –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: ~{len(dataloader) * 1.2 / 3600:.1f} —á–∞—Å–æ–≤ –Ω–∞ —ç–ø–æ—Ö—É")
    print(f"{'='*60}\n")

    for epoch in range(num_epochs):
        epoch_loss = 0.0
        student_model.train()
        num_batches = 0
        
        for i, (latents, prompts) in enumerate(dataloader):
            try:
                # –û—Å—Ç–∞–≤–ª—è–µ–º –ª–∞—Ç–µ–Ω—Ç—ã –Ω–∞ CPU
                latents = latents.float()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ª–∞—Ç–µ–Ω—Ç–æ–≤
                if latents.dim() == 3:
                    # –ï—Å–ª–∏ –Ω–µ—Ç batch dim, –¥–æ–±–∞–≤–ª—è–µ–º
                    latents = latents.unsqueeze(0)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ª–∞—Ç–µ–Ω—Ç—ã –∏–º–µ—é—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                assert latents.shape[1] == 4, f"–û–∂–∏–¥–∞–µ—Ç—Å—è 4 –∫–∞–Ω–∞–ª–∞, –ø–æ–ª—É—á–µ–Ω–æ {latents.shape[1]}"
                assert latents.shape[2] == 64 and latents.shape[3] == 64, \
                    f"–û–∂–∏–¥–∞–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä 64x64, –ø–æ–ª—É—á–µ–Ω–æ {latents.shape[2]}x{latents.shape[3]}"
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
                text_embeddings = get_text_embeddings(prompts, teacher_model)
                
                # Consistency distillation step –Ω–∞ CPU
                loss = consistency_distillation_step_batch_optimized(
                    latents, text_embeddings, teacher_model, student_model
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN
                if torch.isnan(loss):
                    print(f"‚ö†Ô∏è NaN loss –≤ –±–∞—Ç—á–µ {i}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º...")
                    continue
                
                # –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ
                optimizer.zero_grad()
                loss.backward()
                
                # Gradient clipping –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                torch.nn.utils.clip_grad_norm_(student_model.dit.parameters(), max_norm=1.0)
                
                optimizer.step()
                
                epoch_loss += loss.item()
                num_batches += 1
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                if i % 25 == 0:  # –†–µ–∂–µ –ª–æ–≥–∏—Ä—É–µ–º –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
                    print(f"–≠–ø–æ—Ö–∞ [{epoch+1}/{num_epochs}] | –ë–∞—Ç—á [{i}/{len(dataloader)}] | Loss: {loss.item():.6f}")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {i}: {e}")
                continue
        
        # –°—Ä–µ–¥–Ω–∏–π –ª–æ—Å—Å –∑–∞ —ç–ø–æ—Ö—É
        if num_batches > 0:
            avg_epoch_loss = epoch_loss / num_batches
            losses_history.append(avg_epoch_loss)
            
            print(f"\n{'='*60}")
            print(f"–≠–ø–æ—Ö–∞ {epoch+1} –∑–∞–≤–µ—Ä—à–µ–Ω–∞ | –°—Ä–µ–¥–Ω–∏–π Loss: {avg_epoch_loss:.6f}")
            print(f"{'='*60}\n")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç –∫–∞–∂–¥—É—é —ç–ø–æ—Ö—É
            checkpoint_path = f"student_checkpoint_epoch_{epoch+1}.pt"
            torch.save(student_model.dit.state_dict(), checkpoint_path)
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω —á–µ–∫–ø–æ–∏–Ω—Ç: {checkpoint_path}\n")
        else:
            print(f"‚ö†Ô∏è –≠–ø–æ—Ö–∞ {epoch+1}: –ù–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö –±–∞—Ç—á–µ–π!")
    
    print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    return losses_history

# =======================
# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
# =======================
if __name__ == "__main__":
    print("üñ•Ô∏è  –ó–∞–ø—É—Å–∫ Consistency Distillation –Ω–∞ CPU (–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)")
    print("üöÄ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò: batch_size=4, num_workers=0, float32, 5 —ç–ø–æ—Ö")
    print("‚è±Ô∏è  –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: ~3-4 —á–∞—Å–∞ (–≤–º–µ—Å—Ç–æ 15 —á–∞—Å–æ–≤)")
    
    # –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    latents_dir = r"C:\newTry2\train\datadir\latents_good"
    prompts_dir = r"C:\newTry2\train\datadir\prompts_good"
    
    # =======================
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π —É—á–∏—Ç–µ–ª—è –∏ —Å—Ç—É–¥–µ–Ω—Ç–∞ –Ω–∞ CPU
    # =======================
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —É—á–∏—Ç–µ–ª—è –Ω–∞ CPU...")
    try:
        teacher_model = create_latent_diffusion(
            latent_res=64,
            in_channels=4,
            pos_interp_scale=2.0,
            precomputed_latents=False,
            dtype="float32"
        )
        print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞, –æ—Å—Ç–∞–≤–ª—è–µ–º –Ω–∞ CPU...")
        teacher_model = teacher_model.to("cpu")
        print("‚úÖ –ú–æ–¥–µ–ª—å –æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–∞ CPU")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
        exit(1)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ —É—á–∏—Ç–µ–ª—è
    print("–ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ —É—á–∏—Ç–µ–ª—è...")
    try:
        teacher_weights = torch.load("./micro_diffusion/trained_models/teacher.pt", map_location="cpu")
        teacher_model.dit.load_state_dict(teacher_weights, strict=False)
        teacher_model.eval()
        print("‚úÖ –ú–æ–¥–µ–ª—å —É—á–∏—Ç–µ–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ CPU")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤–µ—Å–æ–≤: {e}")
        exit(1)

    print("\n–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å—Ç—É–¥–µ–Ω—Ç–∞ –Ω–∞ CPU...")
    student_model = create_latent_diffusion(
        latent_res=64,
        in_channels=4,
        pos_interp_scale=2.0,
        precomputed_latents=False,
        dtype="float32"
    ).to("cpu")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—É–¥–µ–Ω—Ç–∞ –≤–µ—Å–∞–º–∏ —É—á–∏—Ç–µ–ª—è
    student_model.dit.load_state_dict(teacher_weights, strict=False)
    student_model.train()
    print("‚úÖ –ú–æ–¥–µ–ª—å —Å—Ç—É–¥–µ–Ω—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –≤–µ—Å–∞–º–∏ —É—á–∏—Ç–µ–ª—è –Ω–∞ CPU")

    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞
    optimizer = optim.Adam(student_model.dit.parameters(), lr=1e-5)
    print(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω —Å lr={1e-5}\n")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä (–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    dataset = LatentPromptDataset(latents_dir, prompts_dir)
    dataloader = DataLoader(
        dataset, 
        batch_size=4,  # –£–≤–µ–ª–∏—á–∏–ª–∏ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        shuffle=True, 
        num_workers=0,  # –û—Ç–∫–ª—é—á–∞–µ–º multiprocessing –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        collate_fn=custom_collate
    )
    print(f"‚úÖ DataLoader —Å–æ–∑–¥–∞–Ω: {len(dataset)} —Å—ç–º–ø–ª–æ–≤, batch_size=4, num_workers=0\n")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ (–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)
    num_epochs = 5
    print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {num_epochs} —ç–ø–æ—Ö...")
    print(f"‚è±Ô∏è  –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: ~{len(dataloader) * 1.2 * num_epochs / 3600:.1f} —á–∞—Å–æ–≤")
    
    losses = train_consistency_distillation_batch_optimized(
        dataloader, teacher_model, student_model, optimizer, num_epochs
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
    final_model_path = "student_final_batch_optimized.pt"
    torch.save(student_model.dit.state_dict(), final_model_path)
    print(f"\nüíæ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {final_model_path}")
    
    # –ì—Ä–∞—Ñ–∏–∫ –ª–æ—Å—Å–∞
    plt.figure(figsize=(10, 6))
    plt.plot(range(1, num_epochs + 1), losses, marker='o', linewidth=2)
    plt.xlabel('–≠–ø–æ—Ö–∞', fontsize=12)
    plt.ylabel('Loss', fontsize=12)
    plt.title('Consistency Distillation Training Loss (Batch Optimized)', fontsize=14)
    plt.grid(True, alpha=0.3)
    plt.savefig('training_loss_batch_optimized.png', dpi=150, bbox_inches='tight')
    print(f"üìä –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: training_loss_batch_optimized.png")

