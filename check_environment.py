"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è Consistency Distillation
"""
import sys
import os

print("="*60)
print("–ü–†–û–í–ï–†–ö–ê –û–ö–†–£–ñ–ï–ù–ò–Ø")
print("="*60)

# 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ Python
print(f"Python –≤–µ—Ä—Å–∏—è: {sys.version}")
print(f"Python –ø—É—Ç—å: {sys.executable}")

# 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch
try:
    import torch
    print(f"\n‚úÖ PyTorch: {torch.__version__}")
    print(f"‚úÖ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"‚úÖ CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
        print(f"‚úÖ GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {torch.cuda.device_count()}")
        print(f"‚úÖ –¢–µ–∫—É—â–µ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {torch.cuda.current_device()}")
        print(f"‚úÖ –ò–º—è GPU: {torch.cuda.get_device_name(0)}")
        print(f"‚úÖ –ü–∞–º—è—Ç—å GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
except ImportError as e:
    print(f"‚ùå PyTorch –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")

# 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ micro_diffusion
try:
    from micro_diffusion.micro_diffusion.models.model import create_latent_diffusion
    print(f"\n‚úÖ micro_diffusion –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
except ImportError as e:
    print(f"‚ùå micro_diffusion –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")

# 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ composer
try:
    import composer
    print(f"‚úÖ composer –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
except ImportError as e:
    print(f"‚ùå composer –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")

# 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
latents_dir = r"C:\newTry2\train\datadir\latents"
prompts_dir = r"C:\newTry2\train\datadir\prompts"

print(f"\nüìÅ –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö:")
print(f"   –õ–∞—Ç–µ–Ω—Ç—ã: {os.path.exists(latents_dir)} ({len(os.listdir(latents_dir)) if os.path.exists(latents_dir) else 0} —Ñ–∞–π–ª–æ–≤)")
print(f"   –ü—Ä–æ–º–ø—Ç—ã: {os.path.exists(prompts_dir)} ({len(os.listdir(prompts_dir)) if os.path.exists(prompts_dir) else 0} —Ñ–∞–π–ª–æ–≤)")

# 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Å–æ–≤ —É—á–∏—Ç–µ–ª—è
teacher_path = "./micro_diffusion/trained_models/teacher.pt"
print(f"\nü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Å–æ–≤ —É—á–∏—Ç–µ–ª—è:")
print(f"   –§–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {os.path.exists(teacher_path)}")
if os.path.exists(teacher_path):
    size_mb = os.path.getsize(teacher_path) / 1024**2
    print(f"   –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {size_mb:.1f} MB")

print("\n" + "="*60)
print("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
print("="*60)

if not torch.cuda.is_available():
    print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - –Ω—É–∂–Ω–∞ GPU –≤–µ—Ä—Å–∏—è PyTorch")
    print("   –†–µ—à–µ–Ω–∏–µ: pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121")
else:
    print("‚úÖ CUDA —Ä–∞–±–æ—Ç–∞–µ—Ç - –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ!")

if not os.path.exists(teacher_path):
    print("‚ùå –í–µ—Å–∞ —É—á–∏—Ç–µ–ª—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    print(f"   –û–∂–∏–¥–∞–µ—Ç—Å—è: {teacher_path}")

print("\nüöÄ –ï—Å–ª–∏ –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã, –∑–∞–ø—É—Å—Ç–∏—Ç–µ:")
print("   python train.py")
print("="*60)



