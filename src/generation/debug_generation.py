import os
import torch
from micro_diffusion.micro_diffusion.models.model import create_latent_diffusion
from PIL import Image
import numpy as np

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

def get_text_embeddings(prompts, model, device="cuda"):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
    tokenized = model.tokenizer.tokenize(prompts)
    input_ids = tokenized['input_ids'].to(device)
    
    with torch.no_grad():
        text_embeddings = model.text_encoder.encode(input_ids)[0]
    
    return text_embeddings

if __name__ == "__main__":
    print("=" * 80)
    print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ì–ï–ù–ï–†–ê–¶–ò–ò")
    print("=" * 80)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º CUDA
    if not torch.cuda.is_available():
        print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞!")
        exit(1)
    
    print(f"‚úÖ CUDA: {torch.cuda.get_device_name(0)}")
    
    # –ü—É—Ç—å –∫ –≤–µ—Å–∞–º —É—á–∏—Ç–µ–ª—è
    teacher_weights_path = "./micro_diffusion/micro_diffusion/trained_models/teacher.pt"
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —É—á–∏—Ç–µ–ª—è –Ω–∞ GPU
    print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —É—á–∏—Ç–µ–ª—è –Ω–∞ GPU (Float16)...")
    teacher_model = create_latent_diffusion(
        latent_res=64,
        in_channels=4,
        pos_interp_scale=2.0,
        precomputed_latents=False,
        dtype="float16"
    ).to("cuda")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ —É—á–∏—Ç–µ–ª—è
    print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤ —É—á–∏—Ç–µ–ª—è...")
    teacher_weights = torch.load(teacher_weights_path, map_location="cuda")
    teacher_model.dit.load_state_dict(teacher_weights, strict=False)
    teacher_model.eval()
    print("‚úÖ –ú–æ–¥–µ–ª—å —É—á–∏—Ç–µ–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏
    print("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏:")
    has_nan = False
    for name, param in teacher_model.dit.named_parameters():
        if torch.isnan(param).any():
            print(f"   ‚ùå NaN –≤ {name}")
            has_nan = True
    
    if not has_nan:
        print("   ‚úÖ –í–µ—Å–∞ –º–æ–¥–µ–ª–∏ –≤ –ø–æ—Ä—è–¥–∫–µ (–Ω–µ—Ç NaN)")
    
    # –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
    prompt = "A beautiful sunset over mountains"
    
    print(f"\nüé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è: '{prompt}'")
    
    with torch.no_grad():
        # 1. –¢–µ–∫—Å—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        print("\n1Ô∏è‚É£ –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
        text_embeddings = get_text_embeddings([prompt], teacher_model, device="cuda")
        print(f"   Shape: {text_embeddings.shape}")
        print(f"   Range: [{text_embeddings.min():.3f}, {text_embeddings.max():.3f}]")
        print(f"   Has NaN: {torch.isnan(text_embeddings).any()}")
        
        # 2. –ù–∞—á–∞–ª—å–Ω—ã–π —à—É–º
        print("\n2Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —à—É–º–∞...")
        latent_shape = (1, 4, 64, 64)
        latents = torch.randn(latent_shape, device="cuda")
        print(f"   Shape: {latents.shape}")
        print(f"   Range: [{latents.min():.3f}, {latents.max():.3f}]")
        
        # 3. EDM –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        print("\n3Ô∏è‚É£ EDM –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:")
        sigma_min = teacher_model.edm_config.sigma_min
        sigma_max = teacher_model.edm_config.sigma_max
        rho = teacher_model.edm_config.rho
        print(f"   sigma_min: {sigma_min}")
        print(f"   sigma_max: {sigma_max}")
        print(f"   rho: {rho}")
        
        # 4. –î–µ–Ω–æ–π–∑–∏–Ω–≥ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π - 4 —à–∞–≥–∞)
        print("\n4Ô∏è‚É£ –î–µ–Ω–æ–π–∑–∏–Ω–≥ (4 —à–∞–≥–∞)...")
        num_steps = 4
        step_indices = torch.arange(num_steps, device="cuda")
        t_steps = (sigma_max ** (1 / rho) + step_indices / (num_steps - 1) * (sigma_min ** (1 / rho) - sigma_max ** (1 / rho))) ** rho
        t_steps = torch.cat([t_steps, torch.zeros_like(t_steps[:1])])
        
        print(f"   T steps: {t_steps}")
        
        x = latents * t_steps[0]
        print(f"   Initial noisy x: [{x.min():.3f}, {x.max():.3f}]")
        
        for i in range(num_steps):
            t_cur = t_steps[i]
            t_next = t_steps[i + 1]
            
            sigma_batch = torch.full((1,), t_cur, device="cuda")
            
            output = teacher_model.model_forward_wrapper(
                x,
                sigma_batch,
                text_embeddings,
                teacher_model.dit,
                mask_ratio=0.0
            )
            
            denoised = output['sample']
            
            print(f"   Step {i+1}: t_cur={t_cur:.3f}, denoised range=[{denoised.min():.3f}, {denoised.max():.3f}], has_nan={torch.isnan(denoised).any()}")
            
            d = (x - denoised) / t_cur if t_cur > 0 else torch.zeros_like(x)
            x = x + d * (t_next - t_cur)
            
            print(f"           new x range=[{x.min():.3f}, {x.max():.3f}], has_nan={torch.isnan(x).any()}")
        
        print(f"\n   Final latents: [{x.min():.3f}, {x.max():.3f}]")
        print(f"   Has NaN: {torch.isnan(x).any()}")
        print(f"   Has Inf: {torch.isinf(x).any()}")
        
        # 5. –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ VAE
        print("\n5Ô∏è‚É£ –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ VAE...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Å–∞ VAE
        print("   –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Å–æ–≤ VAE decoder:")
        vae_has_nan = False
        for name, param in teacher_model.vae.decoder.named_parameters():
            if torch.isnan(param).any():
                print(f"      ‚ùå NaN –≤ {name}")
                vae_has_nan = True
        
        if not vae_has_nan:
            print("      ‚úÖ –í–µ—Å–∞ VAE –≤ –ø–æ—Ä—è–¥–∫–µ")
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º
        x_scaled = x / 0.13025
        print(f"   Scaled latents: [{x_scaled.min():.3f}, {x_scaled.max():.3f}]")
        print(f"   Dtype: {x_scaled.dtype}")
        
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ float16
        x_scaled = x_scaled.to(torch.float16)
        print(f"   After to(float16): [{x_scaled.min():.3f}, {x_scaled.max():.3f}]")
        
        images = teacher_model.vae.decode(x_scaled).sample
        print(f"   Decoded images: {images.shape}")
        print(f"   Range: [{images.min():.3f}, {images.max():.3f}]")
        print(f"   Has NaN: {torch.isnan(images).any()}")
        print(f"   Has Inf: {torch.isinf(images).any()}")
        
        # 6. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        print("\n6Ô∏è‚É£ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        images_norm = (images / 2 + 0.5).clamp(0, 1)
        print(f"   After normalization: [{images_norm.min():.3f}, {images_norm.max():.3f}]")
        
        # –í numpy
        images_np = images_norm.cpu().permute(0, 2, 3, 1).numpy()
        print(f"   Numpy shape: {images_np.shape}")
        print(f"   Numpy range: [{images_np.min():.3f}, {images_np.max():.3f}]")
        
        # –í uint8
        images_uint8 = (images_np * 255).round().astype("uint8")
        print(f"   Uint8 range: [{images_uint8.min()}, {images_uint8.max()}]")
        print(f"   Unique values: {len(np.unique(images_uint8))}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        os.makedirs("debug_outputs", exist_ok=True)
        
        # –í–∞—Ä–∏–∞–Ω—Ç 1: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π
        img1 = Image.fromarray(images_uint8[0])
        img1.save("debug_outputs/debug_standard.png")
        print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: debug_outputs/debug_standard.png")
        
        # –í–∞—Ä–∏–∞–Ω—Ç 2: MinMax –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        images_minmax = images_np[0]
        images_minmax = (images_minmax - images_minmax.min()) / (images_minmax.max() - images_minmax.min() + 1e-8)
        images_minmax = (images_minmax * 255).round().astype("uint8")
        img2 = Image.fromarray(images_minmax)
        img2.save("debug_outputs/debug_minmax.png")
        print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: debug_outputs/debug_minmax.png")
        
        # –í–∞—Ä–∏–∞–Ω—Ç 3: –ë–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ /2 + 0.5
        images_raw = images.clamp(0, 1).cpu().permute(0, 2, 3, 1).numpy()
        images_raw = (images_raw * 255).round().astype("uint8")
        img3 = Image.fromarray(images_raw[0])
        img3.save("debug_outputs/debug_raw.png")
        print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: debug_outputs/debug_raw.png")
    
    print("\n" + "=" * 80)
    print("üéâ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
    print("=" * 80)
    print("üìÅ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞–ø–∫—É debug_outputs/")
    print("   - debug_standard.png (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)")
    print("   - debug_minmax.png (MinMax –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)")
    print("   - debug_raw.png (–±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)")
    print("=" * 80)










