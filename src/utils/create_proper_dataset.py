#!/usr/bin/env python3
"""
üìä –°–û–ó–î–ê–ù–ò–ï –ü–†–ê–í–ò–õ–¨–ù–û–ì–û –î–ê–¢–ê–°–ï–¢–ê
================================
–°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç —Å –ª–∞—Ç–µ–Ω—Ç–∞–º–∏ + —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
"""
import torch
import torch.nn as nn
import numpy as np
import os
import sys
from tqdm import tqdm

sys.path.append('/home/ubuntu/train/train/micro_diffusion')

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫
from proper_text_embeddings import ProperTextEncoder

class ProperDataset:
    """–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å –ª–∞—Ç–µ–Ω—Ç–∞–º–∏ –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏"""
    
    def __init__(self, latents_dir, prompts_dir, text_encoder, device="cuda"):
        self.latents_dir = latents_dir
        self.prompts_dir = prompts_dir
        self.text_encoder = text_encoder
        self.device = device
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
        self.latent_files = sorted([f for f in os.listdir(latents_dir) if f.endswith('.pt')])
        self.prompt_files = sorted([f for f in os.listdir(prompts_dir) if f.endswith('.txt')])
        
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(self.latent_files)} –ª–∞—Ç–µ–Ω—Ç–æ–≤")
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(self.prompt_files)} –ø—Ä–æ–º–ø—Ç–æ–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
        if len(self.latent_files) != len(self.prompt_files):
            print("‚ö†Ô∏è  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∞—Ç–µ–Ω—Ç–æ–≤ –∏ –ø—Ä–æ–º–ø—Ç–æ–≤ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç!")
        
        self.length = min(len(self.latent_files), len(self.prompt_files))
        print(f"üìä –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {self.length}")
    
    def __len__(self):
        return self.length
    
    def __getitem__(self, idx):
        """–ü–æ–ª—É—á–∞–µ—Ç –æ–±—Ä–∞–∑–µ—Ü: –ª–∞—Ç–µ–Ω—Ç—ã + —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª–∞—Ç–µ–Ω—Ç—ã
            latent_file = self.latent_files[idx]
            latent_path = os.path.join(self.latents_dir, latent_file)
            latents = torch.load(latent_path, map_location=self.device).to(torch.float32)  # ‚Üê Float32 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç
            prompt_file = self.prompt_files[idx]
            prompt_path = os.path.join(self.prompts_dir, prompt_file)
            with open(prompt_path, 'r', encoding='utf-8') as f:
                prompt = f.read().strip()
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            text_embeddings = self.text_encoder.encode_text(prompt).to(torch.float32)  # ‚Üê Float32 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            
            return {
                'latents': latents,
                'text_embeddings': text_embeddings,
                'prompt': prompt,
                'latent_file': latent_file,
                'prompt_file': prompt_file
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –æ–±—Ä–∞–∑—Ü–∞ {idx}: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π –æ–±—Ä–∞–∑–µ—Ü
            return {
                'latents': torch.randn(4, 64, 64, device=self.device),
                'text_embeddings': torch.randn(1, 77, 1024, device=self.device),
                'prompt': "Error loading sample",
                'latent_file': f"error_{idx}.pt",
                'prompt_file': f"error_{idx}.txt"
            }

def create_proper_dataset():
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç"""
    print("üìä –°–û–ó–î–ê–ù–ò–ï –ü–†–ê–í–ò–õ–¨–ù–û–ì–û –î–ê–¢–ê–°–ï–¢–ê")
    print("=" * 50)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"üñ•Ô∏è –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    # –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    latents_dir = "/home/ubuntu/train/train/datadir/latents_good"
    prompts_dir = "/home/ubuntu/train/train/datadir/prompts_good"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–æ–∫
    if not os.path.exists(latents_dir):
        print(f"‚ùå –ü–∞–ø–∫–∞ –ª–∞—Ç–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {latents_dir}")
        return None
    
    if not os.path.exists(prompts_dir):
        print(f"‚ùå –ü–∞–ø–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {prompts_dir}")
        return None
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫
    print("\nüîß –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫...")
    text_encoder = ProperTextEncoder(device)
    
    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    print("\nüìä –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç...")
    dataset = ProperDataset(latents_dir, prompts_dir, text_encoder, device)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    print("\nüß™ –¢–ï–°–¢–ò–†–£–ï–ú –î–ê–¢–ê–°–ï–¢:")
    print("=" * 30)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 5 –æ–±—Ä–∞–∑—Ü–æ–≤
    for i in range(min(5, len(dataset))):
        print(f"\nüìä –û–±—Ä–∞–∑–µ—Ü {i+1}:")
        
        try:
            sample = dataset[i]
            
            print(f"üìä –õ–∞—Ç–µ–Ω—Ç—ã: {sample['latents'].shape}")
            print(f"üìä –¢–µ–∫—Å—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: {sample['text_embeddings'].shape}")
            print(f"üìù –ü—Ä–æ–º–ø—Ç: '{sample['prompt']}'")
            print(f"üìÅ –§–∞–π–ª –ª–∞—Ç–µ–Ω—Ç–æ–≤: {sample['latent_file']}")
            print(f"üìÅ –§–∞–π–ª –ø—Ä–æ–º–ø—Ç–∞: {sample['prompt_file']}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
            latents_ok = not torch.isnan(sample['latents']).any() and not torch.isinf(sample['latents']).any()
            embeddings_ok = not torch.isnan(sample['text_embeddings']).any() and not torch.isinf(sample['text_embeddings']).any()
            
            print(f"üìä –õ–∞—Ç–µ–Ω—Ç—ã OK: {'‚úÖ' if latents_ok else '‚ùå'}")
            print(f"üìä –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ OK: {'‚úÖ' if embeddings_ok else '‚ùå'}")
            
            if latents_ok and embeddings_ok:
                print("‚úÖ –û–ë–†–ê–ó–ï–¶ –•–û–†–û–®–ò–ô!")
            else:
                print("‚ùå –û–ë–†–ê–ó–ï–¶ –ü–õ–û–•–û–ô!")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—Ä–∞–∑—Ü–∞ {i}: {e}")
            continue
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–ê–¢–ê–°–ï–¢–ê:")
    print(f"üìä –†–∞–∑–º–µ—Ä: {len(dataset)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    print(f"üìä –õ–∞—Ç–µ–Ω—Ç—ã: {latents_dir}")
    print(f"üìä –ü—Ä–æ–º–ø—Ç—ã: {prompts_dir}")
    print(f"üìä –¢–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫: ProperTextEncoder")
    
    return dataset

def test_dataset_loading():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    print("üß™ –¢–ï–°–¢ –ó–ê–ì–†–£–ó–ö–ò –î–ê–¢–ê–°–ï–¢–ê")
    print("=" * 40)
    
    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    dataset = create_proper_dataset()
    if dataset is None:
        return
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º DataLoader
    print("\nüîÑ –¢–ï–°–¢–ò–†–£–ï–ú DATALOADER:")
    print("=" * 30)
    
    try:
        from torch.utils.data import DataLoader
        
        dataloader = DataLoader(
            dataset, 
            batch_size=2, 
            shuffle=True, 
            num_workers=0,
            collate_fn=lambda x: x  # –ü—Ä–æ—Å—Ç–∞—è –∫–æ–ª–ª–∞—Ü–∏—è
        )
        
        print(f"‚úÖ DataLoader —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
        print(f"üìä Batch size: 2")
        print(f"üìä Shuffle: True")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –±–∞—Ç—á–∞
        print("\nüìä –¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –±–∞—Ç—á–∞...")
        for i, batch in enumerate(dataloader):
            print(f"üìä –ë–∞—Ç—á {i+1}: {len(batch)} –æ–±—Ä–∞–∑—Ü–æ–≤")
            
            for j, sample in enumerate(batch):
                print(f"   üìä –û–±—Ä–∞–∑–µ—Ü {j+1}: –ª–∞—Ç–µ–Ω—Ç—ã {sample['latents'].shape}, —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ {sample['text_embeddings'].shape}")
            
            if i >= 2:  # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3 –±–∞—Ç—á–∞
                break
        
        print("‚úÖ DataLoader —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è DataLoader: {e}")

if __name__ == "__main__":
    test_dataset_loading()
