"""
–ë–´–°–¢–†–ê–Ø –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ª–∞—Ç–µ–Ω—Ç—ã —Å batch processing
"""
import os
import torch
from PIL import Image
from tqdm import tqdm
from micro_diffusion.micro_diffusion.models.model import create_latent_diffusion
import torchvision.transforms as transforms

def convert_images_to_latents_fast(
    images_dir,
    output_latents_dir="datadir/latents_good",
    output_prompts_dir="datadir/prompts_good",
    batch_size=16  # VAE encoder –º–æ–∂–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –±–æ–ª—å—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
):
    """
    –ë–´–°–¢–†–ê–Ø –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ª–∞—Ç–µ–Ω—Ç—ã —Å batch processing
    """
    print("üîÑ –ë–´–°–¢–†–ê–Ø –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ª–∞—Ç–µ–Ω—Ç—ã")
    print("=" * 70)
    print(f"‚ö° Batch size: {batch_size}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º CUDA
    if not torch.cuda.is_available():
        print("‚ö†Ô∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU (–±—É–¥–µ—Ç –º–µ–¥–ª–µ–Ω–Ω–æ)")
        device = "cpu"
        batch_size = 4  # CPU –º–µ–Ω—å—à–µ batch
    else:
        print(f"‚úÖ CUDA: {torch.cuda.get_device_name(0)}")
        device = "cuda"
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    os.makedirs(output_latents_dir, exist_ok=True)
    os.makedirs(output_prompts_dir, exist_ok=True)
    print(f"üìÅ –õ–∞—Ç–µ–Ω—Ç—ã: {output_latents_dir}/")
    print(f"üìÅ –ü—Ä–æ–º–ø—Ç—ã: {output_prompts_dir}/")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å (–Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ VAE)
    print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ VAE –∏–∑ micro_diffusion...")
    model = create_latent_diffusion(
        latent_res=64,
        in_channels=4,
        pos_interp_scale=2.0,
        precomputed_latents=False,
        dtype="bfloat16"
    ).to(device)
    model.eval()
    print("‚úÖ VAE –∑–∞–≥—Ä—É–∂–µ–Ω")
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    transform = transforms.Compose([
        transforms.Resize((512, 512)),
        transforms.ToTensor(),
        transforms.Normalize([0.5], [0.5])
    ])
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.png')])
    print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ {len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    print("\nüîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –ª–∞—Ç–µ–Ω—Ç—ã (–±–∞—Ç—á–∞–º–∏)...")
    print("=" * 70)
    
    successful = 0
    failed = 0
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏
    num_batches = (len(image_files) + batch_size - 1) // batch_size
    
    import time
    start_time = time.time()
    
    for batch_idx in tqdm(range(num_batches), desc="–ë–∞—Ç—á–∏"):
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –±–∞—Ç—á–∞
            start_idx = batch_idx * batch_size
            end_idx = min(start_idx + batch_size, len(image_files))
            batch_files = image_files[start_idx:end_idx]
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–∞—Ç—á–∞
            batch_images = []
            batch_prompts = []
            
            for img_file in batch_files:
                img_path = os.path.join(images_dir, img_file)
                image = Image.open(img_path).convert('RGB')
                image_tensor = transform(image)
                batch_images.append(image_tensor)
                
                # –ß–∏—Ç–∞–µ–º –ø—Ä–æ–º–ø—Ç
                txt_file = img_file.replace('.png', '.txt')
                txt_path = os.path.join(images_dir, txt_file)
                if os.path.exists(txt_path):
                    with open(txt_path, 'r', encoding='utf-8') as f:
                        batch_prompts.append(f.read().strip())
                else:
                    batch_prompts.append("")
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ –±–∞—Ç—á
            batch_tensor = torch.stack(batch_images).to(device)
            
            # –ö–æ–¥–∏—Ä—É–µ–º –í–°–ï –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–∞—Ç—á–∞ –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û —á–µ—Ä–µ–∑ VAE!
            with torch.no_grad():
                latents = model.vae.encode(batch_tensor.to(torch.bfloat16)).latent_dist.sample()
                latents = latents * 0.13025
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –ª–∞—Ç–µ–Ω—Ç—ã –∏ –ø—Ä–æ–º–ø—Ç—ã –∏–∑ –±–∞—Ç—á–∞
            for i, (img_file, prompt) in enumerate(zip(batch_files, batch_prompts)):
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–∞—Ç–µ–Ω—Ç (–ë–ï–ó –ª–∏—à–Ω–µ–π batch dimension)
                latent = latents[i]  # [4, 64, 64] –≤–º–µ—Å—Ç–æ [1, 4, 64, 64]
                latent_filename = img_file.replace('.png', '.pt')
                latent_path = os.path.join(output_latents_dir, latent_filename)
                torch.save(latent.cpu(), latent_path)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–ø—Ç
                txt_filename = img_file.replace('.png', '.txt')
                dst_txt_path = os.path.join(output_prompts_dir, txt_filename)
                with open(dst_txt_path, 'w', encoding='utf-8') as f:
                    f.write(prompt)
                
                successful += 1
            
            # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å –∫–∞–∂–¥—ã–µ 10 –±–∞—Ç—á–µ–π
            if device == "cuda" and (batch_idx + 1) % 10 == 0:
                torch.cuda.empty_cache()
                
        except Exception as e:
            print(f"\n‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {batch_idx}: {e}")
            failed += len(batch_files)
            continue
    
    elapsed_time = time.time() - start_time
    
    print("\n" + "=" * 70)
    print("‚úÖ –ö–û–ù–í–ï–†–¢–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful}")
    print(f"   ‚ùå –û—à–∏–±–æ–∫: {failed}")
    print(f"   ‚è±Ô∏è  –í—Ä–µ–º—è: {elapsed_time/60:.1f} –º–∏–Ω—É—Ç ({elapsed_time/successful:.2f} —Å–µ–∫/–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)")
    print(f"   üöÄ –°–∫–æ—Ä–æ—Å—Ç—å: {successful/(elapsed_time/60):.1f} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π/–º–∏–Ω—É—Ç—É")
    print(f"   üìÅ –õ–∞—Ç–µ–Ω—Ç—ã: {output_latents_dir}/")
    print(f"   üìÅ –ü—Ä–æ–º–ø—Ç—ã: {output_prompts_dir}/")
    print("=" * 70)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –ª–∞—Ç–µ–Ω—Ç–æ–≤
    if successful > 0:
        sample_latent_path = os.path.join(output_latents_dir, sorted(os.listdir(output_latents_dir))[0])
        sample_latent = torch.load(sample_latent_path)
        print(f"\nüìä –†–∞–∑–º–µ—Ä –ª–∞—Ç–µ–Ω—Ç–æ–≤: {sample_latent.shape}")
        print(f"   –û–∂–∏–¥–∞–µ—Ç—Å—è: torch.Size([1, 4, 64, 64])")
    
    print("\nüí° –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:")
    print("   python3 train_true_consistency_distillation.py")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='–ë–´–°–¢–†–ê–Ø –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ª–∞—Ç–µ–Ω—Ç—ã')
    parser.add_argument('--images_dir', type=str, default='dataset_sdxl_turbo', 
                        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏')
    parser.add_argument('--output_latents_dir', type=str, default='datadir/latents_good',
                        help='–í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ª–∞—Ç–µ–Ω—Ç–æ–≤')
    parser.add_argument('--output_prompts_dir', type=str, default='datadir/prompts_good',
                        help='–í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤')
    parser.add_argument('--batch_size', type=int, default=16,
                        help='Batch size (16 –¥–ª—è RTX 3090)')
    
    args = parser.parse_args()
    
    convert_images_to_latents_fast(
        images_dir=args.images_dir,
        output_latents_dir=args.output_latents_dir,
        output_prompts_dir=args.output_prompts_dir,
        batch_size=args.batch_size
    )

