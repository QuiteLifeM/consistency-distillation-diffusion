import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import os
import sys
import time
from tqdm import tqdm
import matplotlib.pyplot as plt
# –ò—Å–ø–æ–ª—å–∑—É–µ–º float32
import psutil

sys.path.append('/home/ubuntu/train/train/micro_diffusion')

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
from micro_diffusion.models.dit import MicroDiT_XL_2, DiT  # ‚Üê –î–æ–±–∞–≤–ª—è–µ–º DiT –¥–ª—è Teacher
from proper_text_embeddings import ProperTextEncoder
from create_proper_dataset import ProperDataset

def get_memory_info():
    """–ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–º—è—Ç–∏"""
    # RAM
    ram = psutil.virtual_memory()
    ram_used = ram.used / (1024**3)  # GB
    ram_total = ram.total / (1024**3)  # GB
    
    # VRAM
    if torch.cuda.is_available():
        vram_allocated = torch.cuda.memory_allocated() / (1024**3)  # GB
        vram_reserved = torch.cuda.memory_reserved() / (1024**3)  # GB
        vram_total = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # GB
    else:
        vram_allocated = vram_reserved = vram_total = 0
    
    return {
        'ram_used': ram_used,
        'ram_total': ram_total,
        'vram_allocated': vram_allocated,
        'vram_reserved': vram_reserved,
        'vram_total': vram_total
    }

def log_memory_usage(iteration, epoch, prefix=""):
    """–õ–æ–≥–∏—Ä—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏"""
    mem = get_memory_info()
    print(f"üíæ –ü–∞–º—è—Ç—å ({prefix} –∏—Ç–µ—Ä–∞—Ü–∏—è {iteration}, —ç–ø–æ—Ö–∞ {epoch}):")
    print(f"   üñ•Ô∏è  RAM: {mem['ram_used']:.1f}/{mem['ram_total']:.1f} GB ({mem['ram_used']/mem['ram_total']*100:.1f}%)")
    print(f"   üéÆ VRAM: {mem['vram_allocated']:.1f}/{mem['vram_total']:.1f} GB ({mem['vram_allocated']/mem['vram_total']*100:.1f}%)")
    print(f"   üìä VRAM –∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ: {mem['vram_reserved']:.1f} GB")

class ConsistencyDistillationModel(nn.Module):
    """–ú–æ–¥–µ–ª—å –¥–ª—è Consistency Distillation"""
    
    def __init__(self, teacher_model, student_model):
        super(ConsistencyDistillationModel, self).__init__()
        self.teacher_model = teacher_model  # –ó–∞–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–π Teacher
        self.student_model = student_model  # –û–±—É—á–∞–µ–º—ã–π Student
        
        # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º Teacher
        for param in self.teacher_model.parameters():
            param.requires_grad = False
    
    def forward(self, x_t, t, text_embeddings):
        """Forward pass –¥–ª—è CD"""
        # Teacher –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å (–∑–∞–º–æ—Ä–æ–∂–µ–Ω)
        with torch.no_grad():
            teacher_output = self.teacher_model(x_t, t, text_embeddings)
            if isinstance(teacher_output, dict):
                teacher_output = teacher_output['sample']
        
        # Student –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç (–æ–±—É—á–∞–µ—Ç—Å—è)
        student_output = self.student_model(x_t, t, text_embeddings)
        if isinstance(student_output, dict):
            student_output = student_output['sample']
        
        return {
            'teacher_output': teacher_output,
            'student_output': student_output
        }

def load_models(device="cuda"):
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏"""
    print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏...")
    
    # Teacher –º–æ–¥–µ–ª—å - DiT-XL –Ω–∞ CPU (–∑–∞–º–æ—Ä–æ–∂–µ–Ω) - —Å–æ–≤–º–µ—Å—Ç–∏–º —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
    print("üß† –ó–∞–≥—Ä—É–∂–∞–µ–º Teacher (DiT-XL) –Ω–∞ CPU...")
    teacher_model = DiT(
        input_size=64,
        patch_size=2,
        in_channels=4,
        dim=1024,  # DiT-XL (—Å–æ–≤–º–µ—Å—Ç–∏–º —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é)
        depth=28,  # DiT-XL
        head_dim=64,
        multiple_of=256,
        caption_channels=1024,
        pos_interp_scale=1.0,
        norm_eps=1e-6,
        depth_init=True,
        qkv_multipliers=[1.0],
        ffn_multipliers=[4.0],
        use_patch_mixer=True,
        patch_mixer_depth=4,
        patch_mixer_dim=768,  # –°–æ–≤–º–µ—Å—Ç–∏–º —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
        patch_mixer_qkv_ratio=1.0,
        patch_mixer_mlp_ratio=1.0,
        use_bias=True,
        num_experts=8,
        expert_capacity=1,
        experts_every_n=2
    )
    
    # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ Teacher
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
        pretrained_models = [
            "/home/ubuntu/train/train/micro_diffusion/pretrained_models/dit_4_channel_37M_real_and_synthetic_data.pt",
            "/home/ubuntu/train/train/micro_diffusion/pretrained_models/dit_4_channel_22M_real_only_data.pt",
            "/home/ubuntu/train/train/micro_diffusion/pretrained_models/dit_4_channel_0.5B_synthetic_data.pt"
        ]
        
        teacher_loaded = False
        for model_path in pretrained_models:
            if os.path.exists(model_path):
                print(f"üîç –ù–∞–π–¥–µ–Ω–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: {os.path.basename(model_path)}")
                teacher_state_dict = torch.load(model_path, map_location="cpu")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–æ–≤
                try:
                    teacher_model.load_state_dict(teacher_state_dict)
                    print(f"‚úÖ –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ Teacher –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ {os.path.basename(model_path)}")
                    teacher_loaded = True
                    break
                except Exception as e:
                    print(f"‚ö†Ô∏è  –ù–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–æ–≤ –¥–ª—è {os.path.basename(model_path)}: {e}")
                    continue
        
        if not teacher_loaded:
            print("‚ö†Ô∏è  –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ Teacher –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—É—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é")
            print("üéØ Teacher –±—É–¥–µ—Ç –æ–±—É—á–µ–Ω —Å –Ω—É–ª—è - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è CD!")
            
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Teacher –≤–µ—Å–æ–≤: {e}")
        print("‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—É—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é")
    
    teacher_model.to("cpu", dtype=torch.float32)
    teacher_model.eval()
    print("‚úÖ Teacher (DiT-Large) –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–∞ CPU")
    
    # Student –º–æ–¥–µ–ª—å - MicroDiT_XL_2 –Ω–∞ GPU (–æ–±—É—á–∞–µ—Ç—Å—è)
    print("üéì –ó–∞–≥—Ä—É–∂–∞–µ–º Student (DiT-Small) –Ω–∞ GPU...")
    student_model = MicroDiT_XL_2(
        input_size=64,
        caption_channels=1024,
        pos_interp_scale=1.0,
        in_channels=4
    )
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Student —Å–ª—É—á–∞–π–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏ (–æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç Teacher)
    def init_weights(m):
        if isinstance(m, torch.nn.Linear):
            if m.weight is not None:
                torch.nn.init.xavier_uniform_(m.weight)
            if m.bias is not None:
                torch.nn.init.zeros_(m.bias)
        elif isinstance(m, torch.nn.LayerNorm):
            if m.weight is not None:
                torch.nn.init.ones_(m.weight)
            if m.bias is not None:
                torch.nn.init.zeros_(m.bias)
    
    student_model.apply(init_weights)
    print("‚úÖ Student –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å–ª—É—á–∞–π–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏")
    
    student_model.to(device, dtype=torch.float32)
    student_model.train()
    print("‚úÖ Student (DiT-Small) –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–∞ GPU")
    
    # –í–∫–ª—é—á–∞–µ–º gradient checkpointing –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
    if hasattr(student_model, 'enable_gradient_checkpointing'):
        student_model.enable_gradient_checkpointing()
        print("‚úÖ Gradient checkpointing –≤–∫–ª—é—á–µ–Ω")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫
    print("üîß –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫...")
    text_encoder = ProperTextEncoder(device)
    
    print("‚úÖ –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    return teacher_model, student_model, text_encoder

def consistency_distillation_step(latents, text_embeddings, cd_model, device="cuda"):
    """–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π CD —à–∞–≥: Student —É—á–∏—Ç—Å—è —É Teacher"""
    try:
        # –°–æ–∑–¥–∞–µ–º —à—É–º
        noise = torch.randn_like(latents)
        
        # –°—ç–º–ø–ª–∏—Ä—É–µ–º –≤—Ä–µ–º—è
        t = torch.rand(1, device=device, dtype=torch.float32)
        
        # –ó–∞—à—É–º–ª—è–µ–º –ª–∞—Ç–µ–Ω—Ç—ã
        noisy_latents = latents + t * noise
        
        # CD –º–æ–¥–µ–ª—å –≤—ã–ø–æ–ª–Ω—è–µ—Ç forward pass
        outputs = cd_model(noisy_latents, t, text_embeddings)
        teacher_output = outputs['teacher_output']
        student_output = outputs['student_output']
        
        # Loss: Student –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ—Ö–æ–∂ –Ω–∞ Teacher
        loss = F.mse_loss(student_output, teacher_output)
        
        # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 5 –∏—Ç–µ—Ä–∞—Ü–∏–π)
        if hasattr(consistency_distillation_step, '_debug_count'):
            consistency_distillation_step._debug_count += 1
        else:
            consistency_distillation_step._debug_count = 1
            
        if consistency_distillation_step._debug_count <= 5:
            print(f"üîç –ò—Ç–µ—Ä–∞—Ü–∏—è {consistency_distillation_step._debug_count}:")
            print(f"   Teacher mean: {teacher_output.mean().item():.6f}, std: {teacher_output.std().item():.6f}")
            print(f"   Student mean: {student_output.mean().item():.6f}, std: {student_output.std().item():.6f}")
            print(f"   Loss: {loss.item():.6f}")
        
        return {
            'total_loss': loss,
            'teacher_output': teacher_output,
            'student_output': student_output,
            't': t
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ CD —à–∞–≥–µ: {e}")
        return None

def train_proper_cd_with_text():
    """–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ CD –æ–±—É—á–µ–Ω–∏–µ —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"üñ•Ô∏è –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
    teacher_model, student_model, text_encoder = load_models(device)
    
    # –°–æ–∑–¥–∞–µ–º CD –º–æ–¥–µ–ª—å
    print("üîß –°–æ–∑–¥–∞–µ–º Consistency Distillation –º–æ–¥–µ–ª—å...")
    cd_model = ConsistencyDistillationModel(teacher_model, student_model)
    cd_model.to(device)
    print("‚úÖ CD –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞")
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
    print("\nüìä –°–æ–∑–¥–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç...")
    latents_dir = "/home/ubuntu/train/train/datadir/latents_good"
    prompts_dir = "/home/ubuntu/train/train/datadir/prompts_good"
    
    dataset = ProperDataset(latents_dir, prompts_dir, text_encoder, device)
    print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç —Å–æ–∑–¥–∞–Ω: {len(dataset)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
    num_epochs = 1  # –¢–µ—Å—Ç–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ
    max_iters = 100  # –¢–µ—Å—Ç–æ–≤—ã–µ –∏—Ç–µ—Ä–∞—Ü–∏–∏
    batch_size = 1  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
    lr = 1e-4
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Ç–æ–ª—å–∫–æ –¥–ª—è Student
    optimizer = torch.optim.SGD(student_model.parameters(), lr=lr, momentum=0.9)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º float32
    print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º float32")
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏
    print("üîß –í–∫–ª—é—á–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏...")
    
    # TF32 –¥–ª—è Ampere GPU (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
    if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8:
        torch.backends.cuda.matmul.allow_tf32 = True
        print("‚úÖ TF32 –≤–∫–ª—é—á–µ–Ω –¥–ª—è Ampere GPU")
    
    # Channels Last –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
    try:
        student_model = student_model.to(memory_format=torch.channels_last)
        print("‚úÖ Channels Last –≤–∫–ª—é—á–µ–Ω")
    except Exception as e:
        print(f"‚ö†Ô∏è  Channels Last –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è: {e}")
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    all_losses = []
    start_time = time.time()
    
    # –ù–∞—á–∞–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å
    log_memory_usage(0, 0, "üöÄ –°–¢–ê–†–¢:")
    
    print(f"\nüß™ –¢–ï–°–¢–û–í–û–ï CD –û–ë–£–ß–ï–ù–ò–ï –° –¢–ï–ö–°–¢–û–í–´–ú –ö–û–ù–î–ò–¶–ò–û–ù–ò–†–û–í–ê–ù–ò–ï–ú")
    print(f"üìä –≠–ø–æ—Ö: {num_epochs}, –ò—Ç–µ—Ä–∞—Ü–∏–π: {max_iters}")
    print(f"üìä –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π: {num_epochs * max_iters}")
    print("=" * 70)
    
    for epoch in range(num_epochs):
        print(f"\nüîÑ –≠–ü–û–•–ê {epoch + 1}/{num_epochs}")
        print("=" * 50)
        
        epoch_losses = []
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
        pbar = tqdm(range(max_iters), desc=f"–≠–ø–æ—Ö–∞ {epoch + 1}/{num_epochs}")
        
        for iteration in pbar:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
                sample_idx = iteration % len(dataset)
                sample = dataset[sample_idx]
                
                latents = sample['latents'].unsqueeze(0).to(device, dtype=torch.float32)
                text_embeddings = sample['text_embeddings'].to(device, dtype=torch.float32)
                prompt = sample['prompt']
                
                print(f"üîß –î–∞–Ω–Ω—ã–µ: latents={latents.dtype}, text_embeddings={text_embeddings.dtype}")
                
                # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π CD —à–∞–≥: Student —É—á–∏—Ç—Å—è —É Teacher
                loss_dict = consistency_distillation_step(
                    latents, text_embeddings, cd_model, device
                )
                
                if loss_dict is None:
                    continue
                
                # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                
                # –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ
                optimizer.zero_grad()
                loss_dict['total_loss'].backward()
                
                # Gradient clipping
                torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=0.5)
                
                optimizer.step()
                
                # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                epoch_losses.append(loss_dict['total_loss'].item())
                all_losses.append(loss_dict['total_loss'].item())
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
                pbar.set_postfix({
                    'Loss': f"{loss_dict['total_loss'].item():.6f}",
                    'Avg': f"{np.mean(epoch_losses):.6f}",
                    'Prompt': prompt[:20] + "..." if len(prompt) > 20 else prompt
                })
                
                # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏ –∫–∞–∂–¥—ã–µ 10 –∏—Ç–µ—Ä–∞—Ü–∏–π
                if iteration % 10 == 0:
                    log_memory_usage(iteration, epoch + 1, "üß† –ú–û–ù–ò–¢–û–†–ò–ù–ì –ü–ê–ú–Ø–¢–ò:")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏ {iteration}: {e}")
                continue
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç–ø–æ—Ö–∏
        if len(epoch_losses) > 0:
            avg_loss = np.mean(epoch_losses)
            print(f"üìä –≠–ø–æ—Ö–∞ {epoch + 1} –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –°—Ä–µ–¥–Ω–∏–π loss: {avg_loss:.6f}")
        else:
            print(f"üìä –≠–ø–æ—Ö–∞ {epoch + 1} –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ù–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π.")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å
    try:
        student_model_cpu = student_model.cpu()
        torch.save(student_model_cpu.state_dict(), 'student_test_cd_final.pt')
        student_model.to(device)
        print(f"üíæ –¢–µ—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: student_test_cd_final.pt")
    except Exception as e:
        print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å: {e}")
    
    # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å
    try:
        plt.figure(figsize=(12, 6))
        plt.plot(all_losses)
        plt.title('–¢–µ—Å—Ç–æ–≤–æ–µ CD –æ–±—É—á–µ–Ω–∏–µ —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º –∫–æ–Ω–¥–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º - –ü–æ—Ç–µ—Ä–∏')
        plt.xlabel('–ò—Ç–µ—Ä–∞—Ü–∏—è')
        plt.ylabel('Loss')
        plt.grid(True)
        plt.savefig('test_cd_losses.png')
        print("üìä –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: test_cd_losses.png")
    except Exception as e:
        print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫: {e}")
    
    total_time = time.time() - start_time
    print(f"\nüéâ –¢–ï–°–¢–û–í–û–ï CD –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time/60:.1f} –º–∏–Ω—É—Ç")
    if len(all_losses) > 0:
        print(f"üìâ –ù–∞—á–∞–ª—å–Ω—ã–π loss: {all_losses[0]:.6f}")
        print(f"üìâ –§–∏–Ω–∞–ª—å–Ω—ã–π loss: {all_losses[-1]:.6f}")
        if all_losses[0] > 0:
            improvement = ((all_losses[0] - all_losses[-1]) / all_losses[0] * 100)
            print(f"üìä –£–ª—É—á—à–µ–Ω–∏–µ: {improvement:.1f}%")
        else:
            print("üìä –£–ª—É—á—à–µ–Ω–∏–µ: –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤—ã—á–∏—Å–ª–∏—Ç—å (–Ω–∞—á–∞–ª—å–Ω—ã–π loss = 0)")
    else:
        print("‚ùå –ù–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π –æ–±—É—á–µ–Ω–∏—è")
    print(f"üíæ –¢–µ—Å—Ç–æ–≤—ã–µ –≤–µ—Å–∞: student_test_cd_final.pt")
    print(f"üìä –¢–µ—Å—Ç–æ–≤—ã–π –≥—Ä–∞—Ñ–∏–∫: test_cd_losses.png")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    print(f"\nüé® –¢–ï–°–¢–ò–†–£–ï–ú –ì–ï–ù–ï–†–ê–¶–ò–Æ –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô:")
    print("=" * 50)
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–∞–±–æ—á–∏–π VAE –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        from diffusers import AutoencoderKL
        vae = AutoencoderKL.from_pretrained("stabilityai/sd-vae-ft-mse", torch_dtype=torch.float32)
        vae.to(device)
        vae.eval()
        print("‚úÖ VAE –∑–∞–≥—Ä—É–∂–µ–Ω –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã
        test_prompts = [
            "A beautiful sunset over mountains",
            "A cozy cabin in a snowy forest",
            "A majestic dragon flying over a medieval castle"
        ]
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        os.makedirs("test_generation_outputs", exist_ok=True)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        student_model.eval()
        with torch.no_grad():
            for i, prompt in enumerate(test_prompts):
                print(f"\nüìù –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º: '{prompt}'")
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
                text_embeddings = text_encoder.encode_text(prompt).to(torch.float32)
                
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–∞—Ç–µ–Ω—Ç—ã
                latents = torch.randn(1, 4, 64, 64, device=device, dtype=torch.float32)
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º (4 —à–∞–≥–∞)
                for step in range(4):
                    t = torch.ones(1, device=device, dtype=torch.float32) * (1.0 - step / 3.0)
                    output = student_model(latents, t, text_embeddings)
                    latents = output['sample'] if isinstance(output, dict) else output
                    print(f"üîÑ –®–∞–≥ {step + 1}/4: t={t.item():.3f}")
                
                # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                latents_fp32 = latents.to(torch.float32)
                decoded_output = vae.decode(latents_fp32)
                decoded_image = decoded_output.sample if hasattr(decoded_output, 'sample') else decoded_output
                
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
                decoded_image = (decoded_image / 2 + 0.5).clamp(0, 1)
                image_tensor = decoded_image[0].cpu()
                image_array = (image_tensor.permute(1, 2, 0).numpy() * 255).astype(np.uint8)
                image_array = np.clip(image_array, 0, 255)
                
                from PIL import Image
                image = Image.fromarray(image_array)
                filename = f"test_generation_outputs/test_generated_{i+1}.png"
                image.save(filename)
                print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filename}")
        
        print(f"\nüé® –ì–ï–ù–ï–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø–∞–ø–∫–µ: test_generation_outputs/")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    train_proper_cd_with_text()