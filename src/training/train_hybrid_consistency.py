import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
from tqdm import tqdm
from micro_diffusion.micro_diffusion.models.model import create_latent_diffusion

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

# =======================
# –ì–ò–ë–†–ò–î–ù–´–ô –ü–û–î–•–û–î: Teacher –Ω–∞ CPU, Student –Ω–∞ GPU
# =======================

class LatentPromptDataset(Dataset):
    def __init__(self, latents_dir, prompts_dir):
        self.latents_dir = latents_dir
        self.prompts_dir = prompts_dir
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
        self.latent_files = sorted([f for f in os.listdir(latents_dir) if f.endswith('.pt')])
        self.prompt_files = sorted([f for f in os.listdir(prompts_dir) if f.endswith('.txt')])
        
        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(self.latent_files)} –ª–∞—Ç–µ–Ω—Ç–æ–≤ –∏ {len(self.prompt_files)} –ø—Ä–æ–º–ø—Ç–æ–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
        if len(self.latent_files) != len(self.prompt_files):
            print(f"‚ö†Ô∏è –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ: {len(self.latent_files)} –ª–∞—Ç–µ–Ω—Ç–æ–≤ vs {len(self.prompt_files)} –ø—Ä–æ–º–ø—Ç–æ–≤")
            min_len = min(len(self.latent_files), len(self.prompt_files))
            self.latent_files = self.latent_files[:min_len]
            self.prompt_files = self.prompt_files[:min_len]
            print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º {min_len} –ø–∞—Ä")
    
    def __len__(self):
        return len(self.latent_files)
    
    def __getitem__(self, idx):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª–∞—Ç–µ–Ω—Ç
        latent_path = os.path.join(self.latents_dir, self.latent_files[idx])
        latent = torch.load(latent_path, map_location="cpu")  # –í—Å–µ–≥–¥–∞ –Ω–∞ CPU —Å–Ω–∞—á–∞–ª–∞
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–º–ø—Ç
        prompt_path = os.path.join(self.prompts_dir, self.prompt_files[idx])
        with open(prompt_path, 'r', encoding='utf-8') as f:
            prompt = f.read().strip()
        
        return latent, prompt

def custom_collate(batch):
    """–ö–∞—Å—Ç–æ–º–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –±–∞—Ç—á–µ–π"""
    latents, prompts = zip(*batch)
    latents = torch.stack(latents)
    return latents, list(prompts)

def get_text_embeddings(prompts, model, device="cpu"):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ"""
    tokenized = model.tokenizer.tokenize(prompts)
    input_ids = tokenized['input_ids'].to(device)
    
    with torch.no_grad():
        text_embeddings = model.text_encoder.encode(input_ids)[0]
    
    return text_embeddings

def consistency_distillation_step_hybrid(latents, text_embeddings, teacher_model, student_model):
    """
    –ì–∏–±—Ä–∏–¥–Ω—ã–π —à–∞–≥ Consistency Distillation:
    - Teacher –Ω–∞ CPU
    - Student –Ω–∞ GPU
    - –î–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ—â–∞—é—Ç—Å—è –º–µ–∂–¥—É —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏
    """
    batch_size = latents.shape[0]
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —à—É–º –∏ —Å–∏–≥–º—É
    rnd_normal = torch.randn([batch_size, 1, 1, 1], device=device)
    sigma = (rnd_normal * teacher_model.edm_config.P_std + teacher_model.edm_config.P_mean).exp()
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è teacher (–Ω–∞ CPU)
    latents_cpu = latents.cpu()
    text_embeddings_cpu = text_embeddings.cpu()
    sigma_cpu = sigma.cpu()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —à—É–º –Ω–∞ CPU
    noise_cpu = torch.randn_like(latents_cpu) * sigma_cpu
    noisy_latents_cpu = latents_cpu + noise_cpu
    
    # Teacher inference –Ω–∞ CPU
    with torch.no_grad():
        teacher_output = teacher_model.model_forward_wrapper(
            noisy_latents_cpu.float(),
            sigma_cpu,
            text_embeddings_cpu.float(),
            teacher_model.dit,
            mask_ratio=0.0
        )
        teacher_denoised = teacher_output['sample']
    
    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ GPU –¥–ª—è student
    noisy_latents_gpu = noisy_latents_cpu.to(device)
    text_embeddings_gpu = text_embeddings_cpu.to(device)
    sigma_gpu = sigma_cpu.to(device)
    teacher_denoised_gpu = teacher_denoised.to(device)
    
    # Student inference –Ω–∞ GPU
    student_output = student_model.model_forward_wrapper(
        noisy_latents_gpu.float(),
        sigma_gpu,
        text_embeddings_gpu.float(),
        student_model.dit,
        mask_ratio=0.0
    )
    student_denoised = student_output['sample']
    
    # Loss –Ω–∞ GPU
    loss = nn.MSELoss()(student_denoised, teacher_denoised_gpu)
    
    return loss

def train_consistency_distillation_hybrid(dataloader, teacher_model, student_model, optimizer, num_epochs=5):
    """
    –ì–∏–±—Ä–∏–¥–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ Consistency Distillation
    Teacher –Ω–∞ CPU, Student –Ω–∞ GPU
    """
    losses_history = []
    
    print(f"\n{'='*60}")
    print(f"üöÄ –ì–ò–ë–†–ò–î–ù–´–ô Consistency Distillation")
    print(f"üéØ Teacher: CPU (MicroDiT_XL_2, 1.16B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)")
    print(f"üéì Student: GPU (RTX 3090)")
    print(f"‚ö° –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏: ~12GB VRAM")
    print(f"‚è±Ô∏è  –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: ~{len(dataloader) * 0.8 * num_epochs / 60:.1f} –º–∏–Ω—É—Ç")
    print(f"{'='*60}\n")

    # –û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è –≤—Å–µ—Ö —ç–ø–æ—Ö
    epoch_pbar = tqdm(range(num_epochs), desc="–ì–∏–±—Ä–∏–¥–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", 
                     bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} —ç–ø–æ—Ö [{elapsed}<{remaining}]')

    for epoch in epoch_pbar:
        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –≤ –Ω–∞—á–∞–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏
        torch.cuda.empty_cache()
        
        epoch_loss = 0.0
        student_model.train()
        num_batches = 0
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –¥–ª—è —ç–ø–æ—Ö–∏
        pbar = tqdm(dataloader, desc=f"–≠–ø–æ—Ö–∞ {epoch+1}/{num_epochs}", 
                   bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')
        
        for i, (latents, prompts) in enumerate(pbar):
            try:
                # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –ª–∞—Ç–µ–Ω—Ç—ã –Ω–∞ GPU
                latents = latents.float().cuda()
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–∞ GPU
                text_embeddings = get_text_embeddings(prompts, teacher_model, device="cuda")
                
                # –ì–∏–±—Ä–∏–¥–Ω—ã–π —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è
                loss = consistency_distillation_step_hybrid(
                    latents, text_embeddings, teacher_model, student_model
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN
                if torch.isnan(loss):
                    print(f"\n‚ö†Ô∏è NaN loss –≤ –±–∞—Ç—á–µ {i}")
                    continue
                
                # –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ
                optimizer.zero_grad()
                loss.backward()
                
                # Gradient clipping –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                torch.nn.utils.clip_grad_norm_(student_model.dit.parameters(), max_norm=1.0)
                
                optimizer.step()
                
                # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞
                torch.cuda.empty_cache()
                
                epoch_loss += loss.item()
                num_batches += 1
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä —Å —Ç–µ–∫—É—â–∏–º loss
                pbar.set_postfix({
                    'Loss': f"{loss.item():.6f}",
                    'Avg': f"{epoch_loss/(num_batches+1):.6f}" if num_batches > 0 else "0.000000"
                })
                    
            except Exception as e:
                print(f"\n‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {i}: {e}")
                continue
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
        pbar.close()
        
        # –°—Ä–µ–¥–Ω–∏–π –ª–æ—Å—Å –∑–∞ —ç–ø–æ—Ö—É
        if num_batches > 0:
            avg_epoch_loss = epoch_loss / num_batches
            losses_history.append(avg_epoch_loss)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
            epoch_pbar.set_postfix({
                'Loss': f"{avg_epoch_loss:.6f}",
                'Batches': f"{num_batches}/{len(dataloader)}"
            })
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç –∫–∞–∂–¥—ã–µ 2 —ç–ø–æ—Ö–∏
            if (epoch + 1) % 2 == 0:
                checkpoint_path = f"student_hybrid_checkpoint_epoch_{epoch+1}.pt"
                torch.save(student_model.dit.state_dict(), checkpoint_path)
                print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω —á–µ–∫–ø–æ–∏–Ω—Ç: {checkpoint_path}")
        else:
            print(f"\n‚ö†Ô∏è –≠–ø–æ—Ö–∞ {epoch+1}: –ù–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö –±–∞—Ç—á–µ–π!")
    
    # –ó–∞–∫—Ä—ã–≤–∞–µ–º –æ–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
    epoch_pbar.close()
    
    print("‚úÖ –ì–∏–±—Ä–∏–¥–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    return losses_history

# =======================
# –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# =======================

if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ –ì–ò–ë–†–ò–î–ù–û–ì–û Consistency Distillation")
    print("üéØ Teacher: CPU | üéì Student: GPU")
    print("‚ö° –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏: ~12GB VRAM")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º CUDA
    if not torch.cuda.is_available():
        print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞!")
        exit(1)
    
    print(f"‚úÖ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.get_device_name(0)}")
    print(f"üìä VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    
    # –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    latents_dir = os.path.join("datadir", "latents_good")
    prompts_dir = os.path.join("datadir", "prompts_good")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
    if not os.path.exists(latents_dir) or not os.path.exists(prompts_dir):
        print(f"‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {latents_dir} –∏–ª–∏ {prompts_dir}")
        exit(1)
    
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã: {latents_dir}, {prompts_dir}")
    
    # =======================
    # –°–û–ó–î–ê–ù–ò–ï –ú–û–î–ï–õ–ï–ô
    # =======================
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —É—á–∏—Ç–µ–ª—è –Ω–∞ CPU
    print("\n–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —É—á–∏—Ç–µ–ª—è –Ω–∞ CPU...")
    teacher_model = create_latent_diffusion(
        latent_res=64,
        in_channels=4,
        pos_interp_scale=2.0,
        precomputed_latents=False,
        dtype="float32"
    ).to("cpu")  # Teacher –Ω–∞ CPU!
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ —É—á–∏—Ç–µ–ª—è –Ω–∞ CPU
    print("–ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ —É—á–∏—Ç–µ–ª—è –Ω–∞ CPU...")
    try:
        teacher_weights = torch.load("./micro_diffusion/micro_diffusion/trained_models/teacher.pt", map_location="cpu")
        teacher_model.dit.load_state_dict(teacher_weights, strict=False)
        teacher_model.eval()  # –£—á–∏—Ç–µ–ª—å –≤—Å–µ–≥–¥–∞ –≤ —Ä–µ–∂–∏–º–µ eval
        print("‚úÖ –ú–æ–¥–µ–ª—å —É—á–∏—Ç–µ–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ CPU")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤–µ—Å–æ–≤: {e}")
        exit(1)
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å—Ç—É–¥–µ–Ω—Ç–∞ –Ω–∞ GPU
    print("\n–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å—Ç—É–¥–µ–Ω—Ç–∞ –Ω–∞ GPU...")
    student_model = create_latent_diffusion(
        latent_res=64,
        in_channels=4,
        pos_interp_scale=2.0,
        precomputed_latents=False,
        dtype="float32"
    ).to("cuda")  # Student –Ω–∞ GPU!
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—É–¥–µ–Ω—Ç–∞ –≤–µ—Å–∞–º–∏ —É—á–∏—Ç–µ–ª—è
    student_model.dit.load_state_dict(teacher_weights, strict=False)
    student_model.train()  # –°—Ç—É–¥–µ–Ω—Ç –≤ —Ä–µ–∂–∏–º–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
    
    print("‚úÖ –ú–æ–¥–µ–ª—å —Å—Ç—É–¥–µ–Ω—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –≤–µ—Å–∞–º–∏ —É—á–∏—Ç–µ–ª—è –Ω–∞ GPU")
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞
    optimizer = optim.Adam(student_model.dit.parameters(), lr=1e-5)
    print(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω —Å lr={1e-5}\n")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    dataset = LatentPromptDataset(latents_dir, prompts_dir)
    dataloader = DataLoader(
        dataset, 
        batch_size=2,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º batch_size –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
        shuffle=True, 
        num_workers=0,  # –ë–µ–∑ multiprocessing –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        collate_fn=custom_collate
    )
    print(f"‚úÖ DataLoader —Å–æ–∑–¥–∞–Ω: {len(dataset)} —Å—ç–º–ø–ª–æ–≤, batch_size=2, num_workers=0\n")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
    num_epochs = 5
    print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –≥–∏–±—Ä–∏–¥–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {num_epochs} —ç–ø–æ—Ö...")
    print(f"‚è±Ô∏è  –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: ~{len(dataloader) * 0.8 * num_epochs / 60:.1f} –º–∏–Ω—É—Ç")
    
    losses = train_consistency_distillation_hybrid(
        dataloader, teacher_model, student_model, optimizer, num_epochs
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...")
    torch.save(student_model.dit.state_dict(), "student_final_hybrid.pt")
    print("‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: student_final_hybrid.pt")
    
    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ loss
    print("\nüìä –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ loss...")
    plt.figure(figsize=(10, 6))
    plt.plot(losses, 'b-', linewidth=2, label='Consistency Distillation Loss')
    plt.title('–ì–∏–±—Ä–∏–¥–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ: Teacher (CPU) + Student (GPU)', fontsize=14, fontweight='bold')
    plt.xlabel('–≠–ø–æ—Ö–∞', fontsize=12)
    plt.ylabel('Loss', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig('hybrid_training_loss.png', dpi=300, bbox_inches='tight')
    print("‚úÖ –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: hybrid_training_loss.png")
    
    print(f"\nüéâ –ì–ò–ë–†–ò–î–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print(f"üìà –§–∏–Ω–∞–ª—å–Ω—ã–π loss: {losses[-1]:.6f}")
    print(f"üíæ –ú–æ–¥–µ–ª—å: student_final_hybrid.pt")
    print(f"üìä –ì—Ä–∞—Ñ–∏–∫: hybrid_training_loss.png")











