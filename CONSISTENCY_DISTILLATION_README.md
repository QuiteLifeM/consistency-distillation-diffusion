# Consistency Distillation –¥–ª—è micro_diffusion

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç —Ä–µ–∞–ª–∏–∑—É–µ—Ç Consistency Distillation –¥–ª—è –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏ –º–æ–¥–µ–ª–∏ micro_diffusion.

## –ß—Ç–æ —Ç–∞–∫–æ–µ Consistency Distillation?

Consistency Distillation - —ç—Ç–æ –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞—Ç—å "—Å—Ç—É–¥–µ–Ω—á–µ—Å–∫—É—é" –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞ –º–µ–Ω—å—à–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤, —á–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è "—É—á–∏—Ç–µ–ª—å—Å–∫–∞—è" –º–æ–¥–µ–ª—å. –°—Ç—É–¥–µ–Ω—Ç –æ–±—É—á–∞–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Ç–æ—Ç –∂–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ–Ω–æ–π–∑–∏–Ω–≥–∞, —á—Ç–æ –∏ —É—á–∏—Ç–µ–ª—å, –¥–ª—è –ª—é–±–æ–≥–æ —É—Ä–æ–≤–Ω—è —à—É–º–∞.

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
train/
‚îú‚îÄ‚îÄ datadir/
‚îÇ   ‚îú‚îÄ‚îÄ latents/          # 4000 –ø—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã—Ö –ª–∞—Ç–µ–Ω—Ç–æ–≤ (.pt —Ñ–∞–π–ª—ã)
‚îÇ   ‚îî‚îÄ‚îÄ prompts/          # 4000 —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ (.txt —Ñ–∞–π–ª—ã)
‚îú‚îÄ‚îÄ micro_diffusion/      # –ö–æ–¥ –º–æ–¥–µ–ª–∏ micro_diffusion
‚îÇ   ‚îî‚îÄ‚îÄ trained_models/
‚îÇ       ‚îî‚îÄ‚îÄ teacher.pt    # –í–µ—Å–∞ —É—á–∏—Ç–µ–ª—è
‚îú‚îÄ‚îÄ train.py              # –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ test_data_loading.py  # –¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
‚îî‚îÄ‚îÄ CONSISTENCY_DISTILLATION_README.md  # –≠—Ç–æ—Ç —Ñ–∞–π–ª
```

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- Python 3.8+
- PyTorch 2.0+
- CUDA-—Å–æ–≤–º–µ—Å—Ç–∏–º–∞—è GPU (–º–∏–Ω–∏–º—É–º 8 GB VRAM)
- –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø–∞–∫–µ—Ç micro_diffusion

## –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–∫—Ä–∏–ø—Ç train.py

### 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö

```python
class LatentPromptDataset(Dataset):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ –ª–∞—Ç–µ–Ω—Ç—ã (4, 64, 64) –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã
    """
```

- –õ–∞—Ç–µ–Ω—Ç—ã: 4-–∫–∞–Ω–∞–ª—å–Ω—ã–µ —Ç–µ–Ω–∑–æ—Ä—ã —Ä–∞–∑–º–µ—Ä–∞ 64x64 (—Ä–µ–∑—É–ª—å—Ç–∞—Ç VAE —ç–Ω–∫–æ–¥–∏–Ω–≥–∞ 512x512 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)
- –ü—Ä–æ–º–ø—Ç—ã: —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

### 2. –ú–æ–¥–µ–ª–∏

**–£—á–∏—Ç–µ–ª—å (Teacher Model):**
- –ó–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏ –∏–∑ `teacher.pt`
- –í—Å–µ–≥–¥–∞ –≤ —Ä–µ–∂–∏–º–µ `eval()` (–Ω–µ –æ–±—É—á–∞–µ—Ç—Å—è)
- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç "—Ü–µ–ª–µ–≤—ã–µ" –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞

**–°—Ç—É–¥–µ–Ω—Ç (Student Model):**
- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –≤–µ—Å–∞–º–∏ —É—á–∏—Ç–µ–ª—è
- –û–±—É—á–∞–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Ç–µ –∂–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —á—Ç–æ –∏ —É—á–∏—Ç–µ–ª—å
- –í —Ä–µ–∂–∏–º–µ `train()`

### 3. Consistency Distillation Step

–î–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞:
1. –ë–µ—Ä–µ–º —á–∏—Å—Ç—ã–π –ª–∞—Ç–µ–Ω—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
2. –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º (—Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–∑ EDM —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)
3. –£—á–∏—Ç–µ–ª—å –¥–µ–ª–∞–µ—Ç –æ–¥–∏–Ω —à–∞–≥ –¥–µ–Ω–æ–π–∑–∏–Ω–≥–∞ ‚Üí –ø–æ–ª—É—á–∞–µ–º `teacher_denoised`
4. –°—Ç—É–¥–µ–Ω—Ç –¥–µ–ª–∞–µ—Ç –æ–¥–∏–Ω —à–∞–≥ –¥–µ–Ω–æ–π–∑–∏–Ω–≥–∞ ‚Üí –ø–æ–ª—É—á–∞–µ–º `student_denoised`
5. –í—ã—á–∏—Å–ª—è–µ–º MSE loss –º–µ–∂–¥—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏: `loss = MSE(student_denoised, teacher_denoised)`
6. –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å–∞ —Å—Ç—É–¥–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ backpropagation

### 4. –û–±—É—á–µ–Ω–∏–µ

```python
train_consistency_distillation(
    dataloader, 
    teacher_model, 
    student_model, 
    optimizer, 
    num_epochs=10
)
```

- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥—ã–µ 10 –±–∞—Ç—á–µ–π
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –∫–∞–∂–¥—ã–µ 2 —ç–ø–æ—Ö–∏
- –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å—Ç—É–¥–µ–Ω—Ç–∞
- –ì—Ä–∞—Ñ–∏–∫ loss'–∞

## –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è

### –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö

```bash
python test_data_loading.py
```

–î–æ–ª–∂–Ω–æ –≤—ã–≤–µ—Å—Ç–∏:
```
‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 4000 –ª–∞—Ç–µ–Ω—Ç–æ–≤ –∏ –ø—Ä–æ–º–ø—Ç–æ–≤
Latent shape: torch.Size([4, 64, 64])
Latent dtype: torch.float32
...
```

### –®–∞–≥ 2: –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è

```bash
python train.py
```

### –ß—Ç–æ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç:
1. –ó–∞–≥—Ä—É–∑–∫–∞ —É—á–∏—Ç–µ–ª—è –∏ —Å—Ç—É–¥–µ–Ω—Ç–∞ (~30 —Å–µ–∫)
2. –°–æ–∑–¥–∞–Ω–∏–µ DataLoader
3. –û–±—É—á–µ–Ω–∏–µ 10 —ç–ø–æ—Ö (~1-2 —á–∞—Å–∞ –Ω–∞ 4000 —Å—ç–º–ø–ª–æ–≤ —Å batch_size=4)
4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤: `student_checkpoint_epoch_2.pt`, `student_checkpoint_epoch_4.pt`, –∏ —Ç.–¥.
5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: `student_final.pt`
6. –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞: `training_loss.png`

## –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

–í `train.py` –º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å:

```python
# –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (–º–µ–Ω—å—à–µ = –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ)
batch_size = 4

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
num_epochs = 10

# Learning rate
lr = 1e-5

# –ß–∞—Å—Ç–æ—Ç–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
if i % 10 == 0:  # –ú–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞ 50, 100, –∏ —Ç.–¥.
```

## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—É–¥–µ–Ω—Ç–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:

```python
from micro_diffusion.micro_diffusion.models.model import create_latent_diffusion
import torch

# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å—Ç—É–¥–µ–Ω—Ç–∞
student_model = create_latent_diffusion(
    latent_res=64,
    in_channels=4,
    pos_interp_scale=2.0,
    precomputed_latents=False,
    dtype="float32"
).to("cuda")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞
student_model.dit.load_state_dict(
    torch.load("student_final.pt", map_location="cuda")
)

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
image = student_model.generate(
    prompt=["a beautiful landscape"],
    guidance_scale=5.0,
    num_inference_steps=10,  # –ú–µ–Ω—å—à–µ —à–∞–≥–æ–≤ —á–µ–º —É —É—á–∏—Ç–µ–ª—è!
    seed=42
)
```

## –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

- **Loss:** –î–æ–ª–∂–µ–Ω —É–º–µ–Ω—å—à–∞—Ç—å—Å—è —Å –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–æ–π (–æ—Ç ~0.1-0.5 –¥–æ ~0.01-0.05)
- **–ö–∞—á–µ—Å—Ç–≤–æ:** –°—Ç—É–¥–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ä–∞–≤–Ω–∏–º–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ —Å —É—á–∏—Ç–µ–ª–µ–º, –Ω–æ –∑–∞ –º–µ–Ω—å—à–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤
- **–°–∫–æ—Ä–æ—Å—Ç—å:** –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤ 2-4 —Ä–∞–∑–∞ –±—ã—Å—Ç—Ä–µ–µ

## Troubleshooting

### –û—à–∏–±–∫–∞: "CUDA out of memory"
- –£–º–µ–Ω—å—à–∏—Ç–µ `batch_size` (–ø–æ–ø—Ä–æ–±—É–π—Ç–µ 2 –∏–ª–∏ 1)
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `torch.cuda.empty_cache()` –º–µ–∂–¥—É —ç–ø–æ—Ö–∞–º–∏

### –û—à–∏–±–∫–∞: "Input height (32) doesn't match model (64)"
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –ª–∞—Ç–µ–Ω—Ç—ã –∏–º–µ—é—Ç —Ä–∞–∑–º–µ—Ä [4, 64, 64]
- –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π `latent_res=64` –¥–ª—è 512px –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

### Loss –Ω–µ —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è
- –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–º–µ–Ω—å—à–∏—Ç—å learning rate (–Ω–∞–ø—Ä–∏–º–µ—Ä, `1e-6`)
- –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—á–∏—Ç–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Å—Ç—É–¥–µ–Ω—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –≤–µ—Å–æ–≤ —É—á–∏—Ç–µ–ª—è

### –ú–µ–¥–ª–µ–Ω–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `num_workers=2` –≤ DataLoader (–Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ –Ω–∞ Windows)
- –£–º–µ–Ω—å—à–∏—Ç–µ —á–∞—Å—Ç–æ—Ç—É –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

–í–æ–∑–º–æ–∂–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–∞:

1. **Multi-step Consistency:** –£—á–∏—Ç—å —Å—Ç—É–¥–µ–Ω—Ç–∞ –¥–µ–ª–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ –¥–µ–Ω–æ–π–∑–∏–Ω–≥–∞
2. **EMA (Exponential Moving Average):** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å EMA –≤–µ—Å–æ–≤ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
3. **Progressive Distillation:** –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–º–µ–Ω—å—à–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤
4. **Curriculum Learning:** –ù–∞—á–∏–Ω–∞—Ç—å —Å –ø—Ä–æ—Å—Ç—ã—Ö —É—Ä–æ–≤–Ω–µ–π —à—É–º–∞, –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É—Å–ª–æ–∂–Ω—è—è

## –°—Å—ã–ª–∫–∏

- [Consistency Models Paper](https://arxiv.org/abs/2303.01469)
- [Progressive Distillation](https://arxiv.org/abs/2202.00512)
- [micro_diffusion Documentation](https://github.com/...)

---

–£–¥–∞—á–∏ –≤ –æ–±—É—á–µ–Ω–∏–∏! üöÄ




