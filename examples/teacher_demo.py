#!/usr/bin/env python3

import torch
import os
import sys
sys.path.append('/home/ubuntu/train/train')

from micro_diffusion.models.model import DiT
from micro_diffusion.models.model import UniversalTextEncoder
from diffusers import AutoencoderKL
import torchvision.transforms as T

def test_teacher_simple():
    device = torch.device('cuda')
    print('üé® –ü–†–û–°–¢–û–ô –¢–ï–°–¢ TEACHER:')
    print('=' * 50)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º VAE
    print('üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º VAE...')
    vae = AutoencoderKL.from_pretrained('stabilityai/sdxl-vae', torch_dtype=torch.float32)
    vae.to(device)
    vae.eval()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º Text Encoder
    print('üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º Text Encoder...')
    text_encoder = UniversalTextEncoder(
        'openclip:hf-hub:apple/DFN5B-CLIP-ViT-H-14-378', 
        dtype='bfloat16', 
        pretrained=True
    )

    # –ó–∞–≥—Ä—É–∂–∞–µ–º Teacher DiT –≤–µ—Å–∞
    print('üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º Teacher DiT –≤–µ—Å–∞...')
    teacher_weights = torch.load('/home/ubuntu/train/train/dit_4_channel_37M_real_and_synthetic_data.pt', map_location='cpu')
    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤–µ—Å–æ–≤: {len(teacher_weights)} –∫–ª—é—á–µ–π")
    
    # –°–æ–∑–¥–∞–µ–º DiT –º–æ–¥–µ–ª—å (–ø–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
    print('üîÑ –°–æ–∑–¥–∞–µ–º DiT –º–æ–¥–µ–ª—å...')
    try:
        # –ü–æ–ø—Ä–æ–±—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã DiT-XL
        teacher_dit = DiT(
            dim=1152,  # DiT-XL —Ä–∞–∑–º–µ—Ä
            depth=28,  # DiT-XL –≥–ª—É–±–∏–Ω–∞
            patch_size=2,
            num_classes=0,  # –ë–µ–∑ –∫–ª–∞—Å—Å–æ–≤
            learn_sigma=False,
            cond_dropout=0.0,
            num_heads=16,
            head_dim=72,
            mlp_ratio=4.0,
            qkv_bias=True,
            patch_mixer_dim=256,
            patch_mixer_depth=4,
            caption_channels=4096
        )
        print("‚úÖ DiT –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è DiT: {e}")
        return

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
    print('üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ –≤ DiT...')
    try:
        teacher_dit.load_state_dict(teacher_weights, strict=False)
        teacher_dit.to(device)
        teacher_dit.eval()
        print("‚úÖ –í–µ—Å–∞ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤: {e}")
        return

    # –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã
    test_prompts = [
        'A beautiful sunset over mountains',
        'A cozy cabin in a snowy forest', 
        'A majestic dragon flying over a medieval castle'
    ]

    os.makedirs('test_teacher_simple_outputs', exist_ok=True)

    with torch.no_grad():
        for i, prompt in enumerate(test_prompts):
            print(f'\nüìù Teacher –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç: {prompt}')
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            text_embeddings = text_encoder(prompt).to(torch.float32)
            print(f"üìä Text embeddings shape: {text_embeddings.shape}")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–∞—Ç–µ–Ω—Ç—ã (—Å–ª—É—á–∞–π–Ω—ã–µ)
            latents = torch.randn(1, 4, 64, 64, device=device, dtype=torch.float32)
            print(f"üìä Latents shape: {latents.shape}")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º (20 —à–∞–≥–æ–≤ –¥–ª—è Teacher)
            print(f'üé® Teacher –≥–µ–Ω–µ—Ä–∞—Ü–∏—è 20 —à–∞–≥–æ–≤...')
            for step in range(20):
                t = torch.ones(1, device=device, dtype=torch.float32) * (1.0 - step / 19.0)
                
                # Teacher inference
                with torch.no_grad():
                    # –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ DiT
                    teacher_output = teacher_dit(
                        latents, t, text_embeddings
                    )
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –ª–∞—Ç–µ–Ω—Ç—ã
                    latents = teacher_output['sample'] if isinstance(teacher_output, dict) else teacher_output
                
                if step % 5 == 0:
                    print(f'üîÑ –®–∞–≥ {step + 1}/20: t={t.item():.3f}, output_mean={latents.mean().item():.4f}')
            
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            latents_fp32 = latents.to(torch.float32)
            decoded_output = vae.decode(latents_fp32)
            decoded_image = decoded_output.sample if hasattr(decoded_output, 'sample') else decoded_output
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PIL
            image = T.ToPILImage()(decoded_image[0].cpu().clamp(-1, 1) * 0.5 + 0.5)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            filename = f'test_teacher_simple_outputs/teacher_simple_{i+1}.png'
            image.save(filename)
            print(f'üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filename}')

    print('\nüé® TEACHER –ü–†–û–°–¢–û–ô –¢–ï–°–¢ –ó–ê–í–ï–†–®–ï–ù!')
    print('üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø–∞–ø–∫–µ: test_teacher_simple_outputs/')

if __name__ == "__main__":
    test_teacher_simple()