#!/usr/bin/env python3
"""
üé® –¢–ï–°–¢ –ì–ï–ù–ï–†–ê–¶–ò–ò Consistency Distillation
=========================================
–¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å student_final_5epochs_consistency.pt
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤ 1-4 —à–∞–≥–∞
- –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- –ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import os
import sys
import time
import matplotlib.pyplot as plt
from PIL import Image

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ micro_diffusion
sys.path.append('/home/ubuntu/train/train/micro_diffusion')

def load_trained_model(device="cuda"):
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å...")
    
    # Student –º–æ–¥–µ–ª—å
    from micro_diffusion.models.dit import DiT
    student_model = DiT(
        input_size=64,
        patch_size=2,
        in_channels=4,
        dim=1152,
        depth=28,
        head_dim=64,
        multiple_of=256,
        caption_channels=1024,
        pos_interp_scale=1.0,
        norm_eps=1e-6,
        depth_init=True,
        qkv_multipliers=[1.0],
        ffn_multipliers=[4.0],
        use_patch_mixer=True,
        patch_mixer_depth=4,
        patch_mixer_dim=512,
        patch_mixer_qkv_ratio=1.0,
        patch_mixer_mlp_ratio=1.0,
        use_bias=True,
        num_experts=8,
        expert_capacity=1,
        experts_every_n=2
    )
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
    model_path = "student_final_5epochs_consistency.pt"
    if os.path.exists(model_path):
        checkpoint = torch.load(model_path, map_location=device)
        student_model.load_state_dict(checkpoint)
        student_model.to(device)
        student_model.eval()
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_path}")
    else:
        print(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
        return None
    
    return student_model

def load_vae_and_text_encoder(device="cuda"):
    """–ó–∞–≥—Ä—É–∂–∞–µ–º VAE –∏ Text Encoder"""
    vae = None
    text_encoder = None
    
    # VAE
    vae_path = "/home/ubuntu/train/train/vae_model.pt"
    if os.path.exists(vae_path):
        vae_checkpoint = torch.load(vae_path, map_location=device)
        from micro_diffusion.models.autoencoder import Autoencoder
        vae = Autoencoder()
        vae.load_state_dict(vae_checkpoint['model_state_dict'])
        vae.to(device)
        vae.eval()
        print("‚úÖ VAE –∑–∞–≥—Ä—É–∂–µ–Ω")
    else:
        print("‚ùå VAE –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    
    # Text Encoder
    text_encoder_path = "/home/ubuntu/train/train/text_encoder.pt"
    if os.path.exists(text_encoder_path):
        text_encoder_checkpoint = torch.load(text_encoder_path, map_location=device)
        from micro_diffusion.models.text_encoder import TextEncoder
        text_encoder = TextEncoder()
        text_encoder.load_state_dict(text_encoder_checkpoint['model_state_dict'])
        text_encoder.to(device)
        text_encoder.eval()
        print("‚úÖ Text Encoder –∑–∞–≥—Ä—É–∂–µ–Ω")
    else:
        print("‚ùå Text Encoder –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    
    return vae, text_encoder

def generate_with_consistency_distillation(student_model, text_prompt, vae=None, text_encoder=None, device="cuda", num_steps=1):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å Consistency Distillation
    """
    print(f"üé® –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: '{text_prompt}'")
    print(f"üîÑ –®–∞–≥–æ–≤: {num_steps}")
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    if text_encoder is not None:
        with torch.no_grad():
            tokenized = text_encoder.tokenizer.tokenize([text_prompt])
            input_ids = tokenized['input_ids'].to(device)
            text_embeddings = text_encoder.encode(input_ids)[0]
            if text_embeddings.dim() == 4:
                text_embeddings = text_embeddings.squeeze(1)
    else:
        # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        text_embeddings = torch.randn(1, 77, 1024, device=device)
        print("‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ text embeddings")
    
    # –ù–∞—á–∏–Ω–∞–µ–º —Å —á–∏—Å—Ç–æ–≥–æ —à—É–º–∞
    latents = torch.randn(1, 4, 64, 64, device=device)
    
    print(f"üìä –ù–∞—á–∞–ª—å–Ω—ã–µ –ª–∞—Ç–µ–Ω—Ç—ã: {latents.shape}")
    print(f"üìä Text embeddings: {text_embeddings.shape}")
    
    # Consistency Distillation –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
    with torch.no_grad():
        if num_steps == 1:
            # –û–¥–∏–Ω —à–∞–≥ - –ø—Ä—è–º–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            t = torch.ones(1, device=device)  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π timestep
            student_output = student_model(latents, t, text_embeddings)
            generated_latents = student_output['sample'] if isinstance(student_output, dict) else student_output
            print("üöÄ –û–¥–∏–Ω —à–∞–≥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏!")
            
        else:
            # –ù–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ - –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ
            for step in range(num_steps):
                t = torch.ones(1, device=device) * (1.0 - step / num_steps)  # –£–º–µ–Ω—å—à–∞–µ–º t
                student_output = student_model(latents, t, text_embeddings)
                generated_latents = student_output['sample'] if isinstance(student_output, dict) else student_output
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ª–∞—Ç–µ–Ω—Ç—ã –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —à–∞–≥–∞
                if step < num_steps - 1:
                    latents = generated_latents
                
                print(f"üîÑ –®–∞–≥ {step + 1}/{num_steps}: t={t.item():.3f}")
    
    print(f"üìä –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–∞—Ç–µ–Ω—Ç—ã: {generated_latents.shape}")
    
    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    if vae is not None:
        with torch.no_grad():
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –ª–∞—Ç–µ–Ω—Ç—ã –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            generated_image = vae.decode(generated_latents)
            print(f"üìä –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {generated_image.shape}")
            return generated_image
    else:
        print("‚ö†Ô∏è  VAE –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ª–∞—Ç–µ–Ω—Ç—ã")
        return generated_latents

def generate_ultra_quality(student_model, text_prompt, vae=None, text_encoder=None, device="cuda"):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ —Å 64 —à–∞–≥–∞–º–∏
    """
    print(f"üé® –ì–ï–ù–ï–†–ê–¶–ò–Ø –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ì–û –ö–ê–ß–ï–°–¢–í–ê: '{text_prompt}'")
    print(f"üöÄ –®–∞–≥–æ–≤: 64 (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ)")
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    if text_encoder is not None:
        with torch.no_grad():
            tokenized = text_encoder.tokenizer.tokenize([text_prompt])
            input_ids = tokenized['input_ids'].to(device)
            text_embeddings = text_encoder.encode(input_ids)[0]
            if text_embeddings.dim() == 4:
                text_embeddings = text_embeddings.squeeze(1)
    else:
        text_embeddings = torch.randn(1, 77, 1024, device=device)
        print("‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ text embeddings")
    
    # –ù–∞—á–∏–Ω–∞–µ–º —Å —á–∏—Å—Ç–æ–≥–æ —à—É–º–∞
    latents = torch.randn(1, 4, 64, 64, device=device)
    
    print(f"üìä –ù–∞—á–∞–ª—å–Ω—ã–µ –ª–∞—Ç–µ–Ω—Ç—ã: {latents.shape}")
    
    # –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ —Å 64 —à–∞–≥–∞–º–∏
    with torch.no_grad():
        for step in range(64):
            # –ü–ª–∞–≤–Ω–æ —É–º–µ–Ω—å—à–∞–µ–º timestep –æ—Ç 1.0 –¥–æ 0.0
            t = torch.ones(1, device=device) * (1.0 - step / 63.0)
            
            student_output = student_model(latents, t, text_embeddings)
            generated_latents = student_output['sample'] if isinstance(student_output, dict) else student_output
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ª–∞—Ç–µ–Ω—Ç—ã –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —à–∞–≥–∞
            latents = generated_latents
            
            if step % 8 == 0:  # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 8 —à–∞–≥–æ–≤
                print(f"üîÑ –®–∞–≥ {step + 1}/64: t={t.item():.3f}")
    
    print(f"üìä –§–∏–Ω–∞–ª—å–Ω—ã–µ –ª–∞—Ç–µ–Ω—Ç—ã: {generated_latents.shape}")
    
    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    if vae is not None:
        with torch.no_grad():
            generated_image = vae.decode(generated_latents)
            print(f"üìä –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {generated_image.shape}")
            return generated_image
    else:
        return generated_latents

def test_consistency_generation():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"üñ•Ô∏è –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
    student_model = load_trained_model(device)
    if student_model is None:
        return
    
    vae, text_encoder = load_vae_and_text_encoder(device)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã
    test_prompts = [
        "A beautiful sunset over mountains",
        "A cute cat playing with yarn", 
        "A futuristic city at night",
        "A majestic eagle soaring through clouds",
        "A cozy cabin in a snowy forest"
    ]
    
    print(f"\nüé® –¢–ï–°–¢–ò–†–£–ï–ú –ì–ï–ù–ï–†–ê–¶–ò–Æ")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_dir = "consistency_generation_outputs"
    os.makedirs(output_dir, exist_ok=True)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤
    num_steps_list = [1, 2, 4, 8, 16, 32]
    
    for num_steps in num_steps_list:
        print(f"\nüöÄ –¢–ï–°–¢: {num_steps} —à–∞–≥(–æ–≤) –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
        print("-" * 30)
        
        for i, prompt in enumerate(test_prompts):
            print(f"\nüìù –ü—Ä–æ–º–ø—Ç {i+1}: {prompt}")
            
            try:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                start_time = time.time()
                generated = generate_with_consistency_distillation(
                    student_model, prompt, vae, text_encoder, device, num_steps
                )
                generation_time = time.time() - start_time
                
                print(f"‚è±Ô∏è –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {generation_time:.2f} —Å–µ–∫—É–Ω–¥")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                if isinstance(generated, torch.Tensor) and generated.dim() == 4:
                    # –≠—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    image_tensor = generated[0].cpu()
                    image_array = (image_tensor.permute(1, 2, 0).numpy() * 255).astype(np.uint8)
                    image = Image.fromarray(image_array)
                    
                    filename = f"{output_dir}/test_{i+1}_{num_steps}steps.png"
                    image.save(filename)
                    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filename}")
                    
                else:
                    # –≠—Ç–æ –ª–∞—Ç–µ–Ω—Ç—ã
                    filename = f"{output_dir}/test_{i+1}_{num_steps}steps_latents.pt"
                    torch.save(generated, filename)
                    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –ª–∞—Ç–µ–Ω—Ç—ã: {filename}")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
                continue
    
    # –¢–ï–°–¢ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ì–û –ö–ê–ß–ï–°–¢–í–ê
    print(f"\nüöÄ –¢–ï–°–¢ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ì–û –ö–ê–ß–ï–°–¢–í–ê (64 —à–∞–≥–∞)")
    print("=" * 50)
    
    ultra_prompts = [
        "A majestic dragon flying over a medieval castle",
        "A cyberpunk cityscape with neon lights and flying cars",
        "A serene Japanese garden with cherry blossoms and a koi pond"
    ]
    
    for i, prompt in enumerate(ultra_prompts):
        print(f"\nüé® –£–õ–¨–¢–†–ê-–ö–ê–ß–ï–°–¢–í–û {i+1}: {prompt}")
        
        try:
            start_time = time.time()
            generated = generate_ultra_quality(
                student_model, prompt, vae, text_encoder, device
            )
            generation_time = time.time() - start_time
            
            print(f"‚è±Ô∏è –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {generation_time:.2f} —Å–µ–∫—É–Ω–¥")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if isinstance(generated, torch.Tensor) and generated.dim() == 4:
                image_tensor = generated[0].cpu()
                image_array = (image_tensor.permute(1, 2, 0).numpy() * 255).astype(np.uint8)
                image = Image.fromarray(image_array)
                
                filename = f"{output_dir}/ultra_quality_{i+1}_64steps.png"
                image.save(filename)
                print(f"üíæ –£–õ–¨–¢–†–ê-–ö–ê–ß–ï–°–¢–í–û —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filename}")
                
            else:
                filename = f"{output_dir}/ultra_quality_{i+1}_64steps_latents.pt"
                torch.save(generated, filename)
                print(f"üíæ –£–õ–¨–¢–†–ê-–ö–ê–ß–ï–°–¢–í–û –ª–∞—Ç–µ–Ω—Ç—ã: {filename}")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–ª—å—Ç—Ä–∞-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            continue
    
    print(f"\nüéâ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø–∞–ø–∫–µ: {output_dir}/")
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(f"\nüìä –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
    print("=" * 30)
    
    for num_steps in num_steps_list:
        print(f"\nüîÑ {num_steps} —à–∞–≥(–æ–≤):")
        for i in range(len(test_prompts)):
            filename = f"{output_dir}/test_{i+1}_{num_steps}steps.png"
            if os.path.exists(filename):
                print(f"  ‚úÖ test_{i+1}_{num_steps}steps.png")
            else:
                print(f"  ‚ùå test_{i+1}_{num_steps}steps.png (–Ω–µ —Å–æ–∑–¥–∞–Ω)")
    
    print(f"\nüöÄ –£–õ–¨–¢–†–ê-–ö–ê–ß–ï–°–¢–í–û (64 —à–∞–≥–∞):")
    for i in range(len(ultra_prompts)):
        filename = f"{output_dir}/ultra_quality_{i+1}_64steps.png"
        if os.path.exists(filename):
            print(f"  ‚úÖ ultra_quality_{i+1}_64steps.png")
        else:
            print(f"  ‚ùå ultra_quality_{i+1}_64steps.png (–Ω–µ —Å–æ–∑–¥–∞–Ω)")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üé® –¢–ï–°–¢ –ì–ï–ù–ï–†–ê–¶–ò–ò CONSISTENCY DISTILLATION")
    print("=" * 60)
    print("üéØ –ú–æ–¥–µ–ª—å: student_final_5epochs_consistency.pt")
    print("üéØ –£–ª—É—á—à–µ–Ω–∏–µ loss: 83.91%")
    print("üéØ –¢–µ—Å—Ç–∏—Ä—É–µ–º: 1, 2, 4, 8, 16, 32 —à–∞–≥–∞")
    print("üöÄ –£–õ–¨–¢–†–ê-–ö–ê–ß–ï–°–¢–í–û: 64 —à–∞–≥–∞ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞!")
    print("=" * 60)
    
    try:
        test_consistency_generation()
        
        print(f"\nüéâ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
        print(f"üìÅ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞–ø–∫—É: consistency_generation_outputs/")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
